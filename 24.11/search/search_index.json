{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>pyslurm is the Python client library for the Slurm Workload Manager</p>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Slurm - Slurm shared library and header files</li> <li>Python - &gt;= 3.6</li> <li>Cython - &gt;= 0.29.37</li> </ul> <p>This Version is for Slurm 24.11.x</p>"},{"location":"#versioning","title":"Versioning","text":"<p>In pyslurm, the versioning scheme follows the official Slurm versioning. The first two numbers (<code>MAJOR.MINOR</code>) always correspond to Slurms Major-Release, for example <code>24.11</code>. The last number (<code>MICRO</code>) is however not tied in any way to Slurms <code>MICRO</code> version, but is instead PySlurm's internal Patch-Level. For example, any pyslurm 24.11.X version should work with any Slurm 24.11.X release.</p>"},{"location":"#installation","title":"Installation","text":"<p>By default, it is searched inside <code>/usr/include</code> for the Header files and in <code>/usr/lib64</code> for Slurms shared-library (<code>libslurm.so</code>) during Installation. For Slurm installations in different locations, you will need to provide the corresponding paths to the necessary files.</p> <p>You can specify those with environment variables (recommended), for example:</p> <pre><code>export SLURM_INCLUDE_DIR=/opt/slurm/24.11/include\nexport SLURM_LIB_DIR=/opt/slurm/24.11/lib\n</code></pre> <p>Then you can proceed to install pyslurm, for example by cloning the Repository:</p> <pre><code>git clone https://github.com/PySlurm/pyslurm.git &amp;&amp; cd pyslurm\nscripts/build.sh\n</code></pre> <p>Also see <code>scripts/build.sh -h</code>. You can specify multiple cores for building with the <code>-j</code> option (also possible to set via environment variable <code>PYSLURM_BUILD_JOBS</code>):</p> <pre><code>scripts/build.sh -j4\n</code></pre> <p>Or simply with <code>pip</code> directly:</p> <pre><code>pip install .\n</code></pre>"},{"location":"#contributors","title":"Contributors","text":"<p>pyslurm is made by contributors like you.</p>"},{"location":"#support","title":"Support","text":"<p>Feel free to ask questions in the GitHub Discussions</p> <p>Found a bug or you are missing a feature? Feel free to open an Issue!</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased-on-the-2411x-branch","title":"Unreleased on the 24.11.x branch","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>New Classes to interact with Database Associations (WIP)<ul> <li><code>pyslurm.db.Association</code></li> <li><code>pyslurm.db.Associations</code></li> </ul> </li> <li>New Classes to interact with Database QoS (WIP)<ul> <li><code>pyslurm.db.QualityOfService</code></li> <li><code>pyslurm.db.QualitiesOfService</code></li> </ul> </li> </ul>"},{"location":"changelog/#24110-2024-12-30","title":"24.11.0 - 2024-12-30","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Support for Slurm 24.11.x</li> </ul>"},{"location":"reference/","title":"pyslurm","text":"<p>The <code>pyslurm</code> package is a wrapper around the Slurm C-API</p> <p>Warning</p> <p>Please note that the <code>pyslurm</code> API is currently being completely reworked. Reworked classes and functions that replace functionality of the old API will be marked as such, with a link to the documentation of its old counterpart.</p> <p>Old API functionality that is already replaced is marked as deprecated, and will be removed at some point in the future.</p> <p>The new reworked classes will be tested thoroughly before making them available here, although it is of course still possible that some bugs may appear here and there, which we will try to identify as best as possible!</p> <p>In addition, since these classes are pretty new, their interface (precisely: attribute names, return types) should not yet be considered 100% stable, and changes may be made in rare cases if it makes sense to do so.</p> <p>If you are using the new-style API, we would like to know your feedback on it!</p>"},{"location":"reference/#reworked-classes","title":"Reworked Classes","text":"<ul> <li>Job API<ul> <li>pyslurm.Job</li> <li>pyslurm.JobStep</li> <li>pyslurm.JobSteps</li> <li>pyslurm.Jobs</li> <li>pyslurm.JobSubmitDescription</li> </ul> </li> <li>Database Job API<ul> <li>pyslurm.db.Job</li> <li>pyslurm.db.JobStep</li> <li>pyslurm.db.Jobs</li> <li>pyslurm.db.JobFilter</li> </ul> </li> <li>Node API<ul> <li>pyslurm.Node</li> <li>pyslurm.Nodes</li> </ul> </li> <li>Partition API<ul> <li>pyslurm.Partition</li> <li>pyslurm.Partitions</li> </ul> </li> <li>New Exceptions<ul> <li>pyslurm.RPCError</li> <li>pyslurm.PyslurmError</li> </ul> </li> <li>New utility functions<ul> <li>pyslurm.utils</li> </ul> </li> </ul>"},{"location":"reference/config/","title":"Config","text":"<p>Warning</p> <p>This API is currently being completely reworked, and is subject to be removed in the future when a replacement is introduced</p>"},{"location":"reference/config/#pyslurm.deprecated.config","title":"<code>pyslurm.deprecated.config</code>","text":"<p>Slurm Config Information.</p>"},{"location":"reference/config/#pyslurm.deprecated.config.display_all","title":"<code>display_all()</code>  <code>method descriptor</code>","text":"<p>Print slurm control configuration information.</p>"},{"location":"reference/config/#pyslurm.deprecated.config.find_id","title":"<code>find_id(keyID=b'')</code>  <code>method descriptor</code>","text":"<p>Retrieve config ID data.</p> <p>Parameters:</p> Name Type Description Default <code>keyID</code> <code>str</code> <p>Config key string to search</p> <code>b''</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of values for given config key</p>"},{"location":"reference/config/#pyslurm.deprecated.config.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Return the slurm control configuration information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Configuration data</p>"},{"location":"reference/config/#pyslurm.deprecated.config.ids","title":"<code>ids()</code>  <code>method descriptor</code>","text":"<p>Return the config IDs from retrieved data.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of config key IDs</p>"},{"location":"reference/config/#pyslurm.deprecated.config.key_pairs","title":"<code>key_pairs()</code>  <code>method descriptor</code>","text":"<p>Return a dict of the slurm control data as key pairs.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of slurm key-pair values</p>"},{"location":"reference/config/#pyslurm.deprecated.config.lastUpdate","title":"<code>lastUpdate()</code>  <code>method descriptor</code>","text":"<p>Get the time (epoch seconds) the retrieved data was updated.</p> <p>Returns:</p> Type Description <code>int</code> <p>Epoch seconds</p>"},{"location":"reference/constants/","title":"constants","text":""},{"location":"reference/constants/#pyslurm.constants","title":"<code>pyslurm.constants</code>","text":"<p>pyslurm common Constants</p>"},{"location":"reference/constants/#pyslurm.constants.UNLIMITED","title":"<code>UNLIMITED = 'UNLIMITED'</code>  <code>module-attribute</code>","text":"<p>Represents an infinite/unlimited value. This is sometimes returned for specific attributes as a value to indicate that there is no restriction for it.</p>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#pyslurm.PyslurmError","title":"<code>pyslurm.PyslurmError</code>","text":"<p>               Bases: <code>builtins.Exception</code></p> <p>The base Exception for all Pyslurm errors.</p>"},{"location":"reference/exceptions/#pyslurm.RPCError","title":"<code>pyslurm.RPCError</code>","text":"<p>               Bases: <code>pyslurm.core.error.PyslurmError</code></p> <p>Exception for handling Slurm RPC errors.</p> <p>Parameters:</p> Name Type Description Default <code>errno</code> <code>int</code> <p>A slurm error number returned by RPC functions. Default is None, which will get the last slurm error automatically.</p> <code>-1</code> <code>msg</code> <code>str</code> <p>An optional, custom error description. If this is set, the errno will not be translated to its string representation.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n... try:\n...     myjob = pyslurm.Job.load(9999)\n... except pyslurm.RPCError as e:\n...     print(\"Loading the Job failed\")\n</code></pre>"},{"location":"reference/frontend/","title":"Frontend","text":"<p>Warning</p> <p>This API is currently being completely reworked, and is subject to be removed in the future when a replacement is introduced</p>"},{"location":"reference/frontend/#pyslurm.deprecated.front_end","title":"<code>pyslurm.deprecated.front_end</code>","text":"<p>Access/update slurm front end node information.</p>"},{"location":"reference/frontend/#pyslurm.deprecated.front_end.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get front end node information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary whose key is the Topology ID</p>"},{"location":"reference/frontend/#pyslurm.deprecated.front_end.ids","title":"<code>ids()</code>  <code>method descriptor</code>","text":"<p>Return the node IDs from retrieved data.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of node IDs</p>"},{"location":"reference/frontend/#pyslurm.deprecated.front_end.lastUpdate","title":"<code>lastUpdate()</code>  <code>method descriptor</code>","text":"<p>Return last time (sepoch seconds) the node data was updated.</p> <p>Returns:</p> Type Description <code>int</code> <p>Epoch seconds</p>"},{"location":"reference/frontend/#pyslurm.deprecated.front_end.load","title":"<code>load()</code>  <code>method descriptor</code>","text":"<p>Load slurm front end node information.</p>"},{"location":"reference/hostlist/","title":"Hostlist","text":"<p>Warning</p> <p>This API is currently being completely reworked, and is subject to be removed in the future when a replacement is introduced</p>"},{"location":"reference/hostlist/#pyslurm.deprecated.hostlist","title":"<code>pyslurm.deprecated.hostlist</code>","text":"<p>Wrapper for Slurm hostlist functions.</p>"},{"location":"reference/hostlist/#pyslurm.deprecated.hostlist.get_list","title":"<code>get_list()</code>  <code>method descriptor</code>","text":"<p>Get the list of hostnames composing the hostlist.</p> <p>For example with a hostlist created with \"tux[1-3]\" -&gt; [ 'tux1', tux2', 'tux3' ].</p> <p>Returns:</p> Type Description <code>list</code> <p>The list of hostnames in case of success or None on error.</p>"},{"location":"reference/job/","title":"Job","text":"<p>Note</p> <p>This supersedes the pyslurm.job class, which will be removed in a future release</p>"},{"location":"reference/job/#pyslurm.Job","title":"<code>pyslurm.Job</code>","text":"<p>A Slurm Job.</p> <p>All attributes in this class are read-only.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>int</code> <p>An Integer representing a Job-ID.</p> required <p>Attributes:</p> Name Type Description <code>steps</code> <code>JobSteps</code> <p>Steps this Job has. Before you can access the Steps data for a Job, you have to call the <code>reload()</code> method of a Job instance or the <code>load_steps()</code> method of a Jobs collection.</p> <code>stats</code> <code>JobStatistics</code> <p>Real-time statistics of a Job. Before you can access the stats data for a Job, you have to call the <code>load_stats</code> method of a Job instance or the Jobs collection.</p> <code>pids</code> <code>dict[str, list]</code> <p>Current Process-IDs of the Job, organized by node name. Before you can access the pids data for a Job, you have to call the <code>load_stats</code> method of a Job instance or the Jobs collection.</p> <code>name</code> <code>str</code> <p>Name of the Job</p> <code>id</code> <code>int</code> <p>Unique ID of the Job.</p> <code>association_id</code> <code>int</code> <p>ID of the Association this Job runs with.</p> <code>account</code> <code>str</code> <p>Name of the Account this Job is runs with.</p> <code>user_id</code> <code>int</code> <p>UID of the User who submitted the Job.</p> <code>user_name</code> <code>str</code> <p>Name of the User who submitted the Job.</p> <code>group_id</code> <code>int</code> <p>GID of the Group that Job runs under.</p> <code>group_name</code> <code>str</code> <p>Name of the Group this Job runs under.</p> <code>priority</code> <code>int</code> <p>Priority of the Job.</p> <code>nice</code> <code>int</code> <p>Nice Value of the Job.</p> <code>qos</code> <code>str</code> <p>QOS Name of the Job.</p> <code>min_cpus_per_node</code> <code>int</code> <p>Minimum Amount of CPUs per Node the Job requested.</p> <code>state</code> <code>str</code> <p>State this Job is currently in.</p> <code>state_reason</code> <code>str</code> <p>A Reason explaining why the Job is in its current state.</p> <code>is_requeueable</code> <code>bool</code> <p>Whether the Job is requeuable or not.</p> <code>requeue_count</code> <code>int</code> <p>Amount of times the Job has been requeued.</p> <code>is_batch_job</code> <code>bool</code> <p>Whether the Job is a batch job or not.</p> <code>node_reboot_required</code> <code>bool</code> <p>Whether the Job requires the Nodes to be rebooted first.</p> <code>dependencies</code> <code>dict</code> <p>Dependencies the Job has to other Jobs.</p> <code>time_limit</code> <code>int</code> <p>Time-Limit, in minutes, for this Job.</p> <code>time_limit_min</code> <code>int</code> <p>Minimum Time-Limit in minutes for this Job.</p> <code>submit_time</code> <code>int</code> <p>Time the Job was submitted, as unix timestamp.</p> <code>eligible_time</code> <code>int</code> <p>Time the Job is eligible to start, as unix timestamp.</p> <code>accrue_time</code> <code>int</code> <p>Job accrue time, as unix timestamp</p> <code>start_time</code> <code>int</code> <p>Time this Job has started execution, as unix timestamp.</p> <code>resize_time</code> <code>int</code> <p>Time the job was resized, as unix timestamp.</p> <code>deadline</code> <code>int</code> <p>Time when a pending Job will be cancelled, as unix timestamp.</p> <code>preempt_eligible_time</code> <code>int</code> <p>Time the Job is eligible for preemption, as unix timestamp.</p> <code>preempt_time</code> <code>int</code> <p>Time the Job was signaled for preemption, as unix timestamp.</p> <code>suspend_time</code> <code>int</code> <p>Last Time the Job was suspended, as unix timestamp.</p> <code>last_sched_evaluation_time</code> <code>int</code> <p>Last time evaluated for Scheduling, as unix timestamp.</p> <code>pre_suspension_time</code> <code>int</code> <p>Amount of seconds the Job ran prior to suspension, as unix timestamp</p> <code>mcs_label</code> <code>str</code> <p>MCS Label for the Job</p> <code>partition</code> <code>str</code> <p>Name of the Partition the Job runs in.</p> <code>submit_host</code> <code>str</code> <p>Name of the Host this Job was submitted from.</p> <code>batch_host</code> <code>str</code> <p>Name of the Host where the Batch-Script is executed.</p> <code>num_nodes</code> <code>int</code> <p>Amount of Nodes the Job has requested or allocated.</p> <code>max_nodes</code> <code>int</code> <p>Maximum amount of Nodes the Job has requested.</p> <code>allocated_nodes</code> <code>str</code> <p>Nodes the Job is currently using. This is only valid when the Job is running. If the Job is pending, it will always return None.</p> <code>required_nodes</code> <code>str</code> <p>Nodes the Job is explicitly requiring to run on.</p> <code>excluded_nodes</code> <code>str</code> <p>Nodes that are explicitly excluded for execution.</p> <code>scheduled_nodes</code> <code>str</code> <p>Nodes the Job is scheduled on by the slurm controller.</p> <code>derived_exit_code</code> <code>int</code> <p>The derived exit code for the Job.</p> <code>derived_exit_code_signal</code> <code>int</code> <p>Signal for the derived exit code.</p> <code>exit_code</code> <code>int</code> <p>Code with which the Job has exited.</p> <code>exit_code_signal</code> <code>int</code> <p>The signal which has led to the exit code of the Job.</p> <code>batch_constraints</code> <code>list</code> <p>Features that node(s) should have for the batch script. Controls where it is possible to execute the batch-script of the job. Also see 'constraints'</p> <code>federation_origin</code> <code>str</code> <p>Federation Origin</p> <code>federation_siblings_active</code> <code>int</code> <p>Federation siblings active</p> <code>federation_siblings_viable</code> <code>int</code> <p>Federation siblings viable</p> <code>cpus</code> <code>int</code> <p>Total amount of CPUs the Job is using. If the Job is still pending, this will be the amount of requested CPUs.</p> <code>cpus_per_task</code> <code>int</code> <p>Number of CPUs per Task used.</p> <code>cpus_per_gpu</code> <code>int</code> <p>Number of CPUs per GPU used.</p> <code>boards_per_node</code> <code>int</code> <p>Number of boards per Node.</p> <code>sockets_per_board</code> <code>int</code> <p>Number of sockets per board.</p> <code>sockets_per_node</code> <code>int</code> <p>Number of sockets per node.</p> <code>cores_per_socket</code> <code>int</code> <p>Number of cores per socket.</p> <code>threads_per_core</code> <code>int</code> <p>Number of threads per core.</p> <code>ntasks</code> <code>int</code> <p>Number of parallel processes.</p> <code>ntasks_per_node</code> <code>int</code> <p>Number of parallel processes per node.</p> <code>ntasks_per_board</code> <code>int</code> <p>Number of parallel processes per board.</p> <code>ntasks_per_socket</code> <code>int</code> <p>Number of parallel processes per socket.</p> <code>ntasks_per_core</code> <code>int</code> <p>Number of parallel processes per core.</p> <code>ntasks_per_gpu</code> <code>int</code> <p>Number of parallel processes per GPU.</p> <code>delay_boot_time</code> <code>int</code> <p>https://slurm.schedmd.com/sbatch.html#OPT_delay-boot, in minutes</p> <code>constraints</code> <code>list</code> <p>A list of features the Job requires nodes to have. In contrast, the 'batch_constraints' option only focuses on the initial batch-script placement. This option however means features to restrict the list of nodes a job is able to execute on in general beyond the initial batch-script.</p> <code>cluster</code> <code>str</code> <p>Name of the cluster the job is executing on.</p> <code>cluster_constraints</code> <code>list</code> <p>A List of features that a cluster should have.</p> <code>reservation</code> <code>str</code> <p>Name of the reservation this Job uses.</p> <code>resource_sharing</code> <code>str</code> <p>Mode controlling how a job shares resources with others.</p> <code>requires_contiguous_nodes</code> <code>bool</code> <p>Whether the Job has allocated a set of contiguous nodes.</p> <code>licenses</code> <code>list</code> <p>List of licenses the Job needs.</p> <code>network</code> <code>str</code> <p>Network specification for the Job.</p> <code>command</code> <code>str</code> <p>The command that is executed for the Job.</p> <code>working_directory</code> <code>str</code> <p>Path to the working directory for this Job.</p> <code>admin_comment</code> <code>str</code> <p>An arbitrary comment set by an administrator for the Job.</p> <code>system_comment</code> <code>str</code> <p>An arbitrary comment set by the slurmctld for the Job.</p> <code>container</code> <code>str</code> <p>The container this Job uses.</p> <code>comment</code> <code>str</code> <p>An arbitrary comment set for the Job.</p> <code>standard_input</code> <code>str</code> <p>The path to the file for the standard input stream.</p> <code>standard_output</code> <code>str</code> <p>The path to the log file for the standard output stream.</p> <code>standard_error</code> <code>str</code> <p>The path to the log file for the standard error stream.</p> <code>required_switches</code> <code>int</code> <p>Number of switches required.</p> <code>max_wait_time_switches</code> <code>int</code> <p>Amount of seconds to wait for the switches.</p> <code>burst_buffer</code> <code>str</code> <p>Burst buffer specification</p> <code>burst_buffer_state</code> <code>str</code> <p>Burst buffer state</p> <code>cpu_frequency_min</code> <code>Union[str, int]</code> <p>Minimum CPU-Frequency requested.</p> <code>cpu_frequency_max</code> <code>Union[str, int]</code> <p>Maximum CPU-Frequency requested.</p> <code>cpu_frequency_governor</code> <code>Union[str, int]</code> <p>CPU-Frequency Governor requested.</p> <code>billable_tres</code> <code>float</code> <p>Amount of billable trackable resources.</p> <code>wckey</code> <code>str</code> <p>Name of the WCKey this Job uses.</p> <code>mail_user</code> <code>list</code> <p>Users that should receive Mails for this Job.</p> <code>mail_types</code> <code>list</code> <p>Mail Flags specified by the User.</p> <code>heterogeneous_id</code> <code>int</code> <p>Heterogeneous job id.</p> <code>heterogeneous_offset</code> <code>int</code> <p>Heterogeneous job offset.</p> <code>temporary_disk_per_node</code> <code>int</code> <p>Temporary disk space in Mebibytes available per Node.</p> <code>array_id</code> <code>int</code> <p>The master Array-Job ID.</p> <code>array_tasks_parallel</code> <code>int</code> <p>Max number of array tasks allowed to run simultaneously.</p> <code>array_task_id</code> <code>int</code> <p>Array Task ID of this Job if it is an Array-Job.</p> <code>array_tasks_waiting</code> <code>str</code> <p>Array Tasks that are still waiting.</p> <code>end_time</code> <code>int</code> <p>Time at which this Job will end, as unix timestamp.</p> <code>run_time</code> <code>int</code> <p>Amount of seconds the Job has been running.</p> <code>cores_reserved_for_system</code> <code>int</code> <p>Amount of cores reserved for System use only.</p> <code>threads_reserved_for_system</code> <code>int</code> <p>Amount of Threads reserved for System use only.</p> <code>memory</code> <code>int</code> <p>Total Amount of Memory this Job has, in Mebibytes</p> <code>memory_per_cpu</code> <code>int</code> <p>Amount of Memory per CPU this Job has, in Mebibytes</p> <code>memory_per_node</code> <code>int</code> <p>Amount of Memory per Node this Job has, in Mebibytes</p> <code>memory_per_gpu</code> <code>int</code> <p>Amount of Memory per GPU this Job has, in Mebibytes</p> <code>gres_per_node</code> <code>dict</code> <p>Generic Resources (e.g. GPU) this Job is using per Node.</p> <code>profile_types</code> <code>list</code> <p>Types for which detailed accounting data is collected.</p> <code>gres_binding</code> <code>str</code> <p>Binding Enforcement of a Generic Resource (e.g. GPU).</p> <code>gres_tasks_per_sharing</code> <code>str</code> <p>Task Sharing of a Generic Resource (e.g. GPU).</p> <code>kill_on_invalid_dependency</code> <code>bool</code> <p>Whether the Job should be killed on an invalid dependency.</p> <code>spreads_over_nodes</code> <code>bool</code> <p>Whether the Job should be spread over as many nodes as possible.</p> <code>is_cronjob</code> <code>bool</code> <p>Whether this Job is a cronjob.</p> <code>cronjob_time</code> <code>str</code> <p>The time specification for the Cronjob.</p> <code>elapsed_cpu_time</code> <code>int</code> <p>Amount of CPU-Time used by the Job so far. This is the result of multiplying the run_time with the amount of cpus requested.</p> <code>run_time_remaining</code> <code>int</code> <p>The amount of seconds the job has still left until hitting the <code>time_limit</code>.</p>"},{"location":"reference/job/#pyslurm.Job.cancel","title":"<code>cancel()</code>  <code>method descriptor</code>","text":"<p>Cancel a Job.</p> <p>Implements the slurm_kill_job RPC.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When cancelling the Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; pyslurm.Job(9999).cancel()\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.get_batch_script","title":"<code>get_batch_script()</code>  <code>method descriptor</code>","text":"<p>Return the content of the script for a Batch-Job.</p> <p>Returns:</p> Type Description <code>str</code> <p>The content of the batch script.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When retrieving the Batch-Script for the Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; script = pyslurm.Job(9999).get_batch_script()\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.get_resource_layout_per_node","title":"<code>get_resource_layout_per_node()</code>  <code>method descriptor</code>","text":"<p>Retrieve the resource layout of this Job on each node.</p> <p>Warning</p> <p>Return type may still be subject to change in the future</p> <p>Returns:</p> Type Description <code>dict</code> <p>Resource layout, where the key is the name of the node and the value another dict with the keys <code>cpu_ids</code>, <code>memory</code> and <code>gres</code>.</p>"},{"location":"reference/job/#pyslurm.Job.hold","title":"<code>hold(mode=None)</code>  <code>method descriptor</code>","text":"<p>Hold a currently pending Job, preventing it from being scheduled.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Determines in which mode the Job should be held. Possible values are <code>user</code> or <code>admin</code>. By default, the Job is held in <code>admin</code> mode, meaning only an Administrator will be able to release the Job again. If you specify the mode as <code>user</code>, the User will also be able to release the job.</p> <code>None</code> <p>Raises:</p> Type Description <code>RPCError</code> <p>When holding the Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Holding a Job (in \"admin\" mode by default)\n&gt;&gt;&gt; pyslurm.Job(9999).hold()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Holding a Job in \"user\" mode\n&gt;&gt;&gt; pyslurm.Job(9999).hold(mode=\"user\")\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.load","title":"<code>load(job_id)</code>  <code>staticmethod</code>","text":"<p>Load information for a specific Job.</p> <p>Implements the slurm_load_job RPC.</p> <p>Note</p> <p>If the Job is not pending, the related Job steps will also be loaded. Job statistics are however not loaded automatically.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>int</code> <p>An Integer representing a Job-ID.</p> required <p>Returns:</p> Type Description <code>Job</code> <p>Returns a new Job instance</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>If requesting the Job information from the slurmctld was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; job = pyslurm.Job.load(9999)\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.load_stats","title":"<code>load_stats()</code>  <code>method descriptor</code>","text":"<p>Load realtime statistics for a Job and its steps.</p> <p>Calling this function returns the Job statistics, and additionally populates the <code>stats</code> and <code>pids</code> attribute of the instance.</p> <p>Returns:</p> Type Description <code>JobStatistics</code> <p>The statistics of the job.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When receiving the Statistics was not</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; job = pyslurm.Job.load(9999)\n&gt;&gt;&gt; stats = job.load_stats()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Print the CPU Time Used\n&gt;&gt;&gt; print(stats.total_cpu_time)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Print the Process-IDs for the whole Job, organized by hostname\n&gt;&gt;&gt; print(job.pids)\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.modify","title":"<code>modify(changes)</code>  <code>method descriptor</code>","text":"<p>Modify a Job.</p> <p>Implements the slurm_update_job RPC.</p> <p>Parameters:</p> Name Type Description Default <code>changes</code> <code>JobSubmitDescription</code> <p>A JobSubmitDescription object which contains all the modifications that should be done on the Job.</p> required <p>Raises:</p> Type Description <code>RPCError</code> <p>When updating the Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Setting the new time-limit to 20 days\n&gt;&gt;&gt; changes = pyslurm.JobSubmitDescription(time_limit=\"20-00:00:00\")\n&gt;&gt;&gt; pyslurm.Job(9999).modify(changes)\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.notify","title":"<code>notify(msg)</code>  <code>method descriptor</code>","text":"<p>Sends a message to the Jobs stdout.</p> <p>Implements the slurm_notify_job RPC.</p> <p>Parameters:</p> Name Type Description Default <code>msg</code> <code>str</code> <p>The message that should be sent.</p> required <p>Raises:</p> Type Description <code>RPCError</code> <p>When sending the message to the Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; pyslurm.Job(9999).notify(\"Hello Friends!\")\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.release","title":"<code>release()</code>  <code>method descriptor</code>","text":"<p>Release a currently held Job, allowing it to be scheduled again.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When releasing a held Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; pyslurm.Job(9999).release()\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.requeue","title":"<code>requeue(hold=False)</code>  <code>method descriptor</code>","text":"<p>Requeue a currently running Job.</p> <p>Implements the slurm_requeue RPC.</p> <p>Parameters:</p> Name Type Description Default <code>hold</code> <code>bool</code> <p>Controls whether the Job should be put in a held state or not. Default for this is <code>False</code>, so it will not be held.</p> <code>False</code> <p>Raises:</p> Type Description <code>RPCError</code> <p>When requeing the Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Requeing a Job while allowing it to be\n&gt;&gt;&gt; # scheduled again immediately\n&gt;&gt;&gt; pyslurm.Job(9999).requeue()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Requeing a Job while putting it in a held state\n&gt;&gt;&gt; pyslurm.Job(9999).requeue(hold=True)\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.send_signal","title":"<code>send_signal(signal, steps='children', hurry=False)</code>  <code>method descriptor</code>","text":"<p>Send a signal to a running Job.</p> <p>Implements the slurm_signal_job RPC.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>Union[str, int]</code> <p>Any valid signal which will be sent to the Job. Can be either a str like <code>SIGUSR1</code>, or simply an int.</p> required <code>steps</code> <code>str</code> <p>Selects which steps should be signaled. Valid values for this are: <code>all</code>, <code>batch</code> and <code>children</code>. The default value is <code>children</code>, where all steps except the batch-step will be signaled. The value <code>batch</code> in contrast means, that only the batch-step will be signaled. With <code>all</code> every step is signaled.</p> <code>'children'</code> <code>hurry</code> <code>bool</code> <p>If True, no burst buffer data will be staged out. The default value is False.</p> <code>False</code> <p>Raises:</p> Type Description <code>RPCError</code> <p>When sending the signal was not successful.</p> <p>Examples:</p> <p>Specifying the signal as a string:</p> <pre><code>&gt;&gt;&gt; from pyslurm import Job\n&gt;&gt;&gt; Job(9999).send_signal(\"SIGUSR1\")\n</code></pre> <p>or passing in a numeric signal:</p> <pre><code>&gt;&gt;&gt; Job(9999).send_signal(9)\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.suspend","title":"<code>suspend()</code>  <code>method descriptor</code>","text":"<p>Suspend a running Job.</p> <p>Implements the slurm_suspend RPC.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When suspending the Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; pyslurm.Job(9999).suspend()\n</code></pre>"},{"location":"reference/job/#pyslurm.Job.to_dict","title":"<code>to_dict()</code>  <code>method descriptor</code>","text":"<p>Job information formatted as a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Job information as dict</p>"},{"location":"reference/job/#pyslurm.Job.unsuspend","title":"<code>unsuspend()</code>  <code>method descriptor</code>","text":"<p>Unsuspend a currently suspended Job.</p> <p>Implements the slurm_resume RPC.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When unsuspending the Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; pyslurm.Job(9999).unsuspend()\n</code></pre>"},{"location":"reference/job/#pyslurm.Jobs","title":"<code>pyslurm.Jobs</code>","text":"<p>               Bases: <code>pyslurm.xcollections.MultiClusterMap</code></p> <p>A <code>Multi Cluster</code> collection of pyslurm.Job objects.</p> <p>Parameters:</p> Name Type Description Default <code>jobs</code> <code>Union[list[int], dict[int, Job], str]</code> <p>Jobs to initialize this collection with.</p> <code>None</code> <code>frozen</code> <code>bool</code> <p>Control whether this collection is <code>frozen</code> when reloading Job information.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>memory</code> <code>int</code> <p>Total amount of memory requested for all Jobs in this collection, in Mebibytes</p> <code>cpus</code> <code>int</code> <p>Total amount of cpus requested for all Jobs in this collection.</p> <code>ntasks</code> <code>int</code> <p>Total amount of tasks requested for all Jobs in this collection.</p> <code>elapsed_cpu_time</code> <code>int</code> <p>Total amount of CPU-Time used by all the Jobs in the collection. This is the result of multiplying the run_time with the amount of cpus requested for each job.</p> <code>frozen</code> <code>bool</code> <p>If this is set to True and the <code>reload()</code> method is called, then ONLY Jobs that already exist in this collection will be reloaded. New Jobs that are discovered will not be added to this collection, but old Jobs which have already been purged from the Slurm controllers memory will not be removed either. The default is False, so old jobs will be removed, and new Jobs will be added - basically the same behaviour as doing Jobs.load().</p> <code>stats</code> <code>JobStatistics</code> <p>Real-time statistics of all Jobs in this collection. Before you can access the stats data for this, you have to call the <code>load_stats</code> method on this collection.</p>"},{"location":"reference/job/#pyslurm.Jobs.load","title":"<code>load(preload_passwd_info=False, frozen=False)</code>  <code>staticmethod</code>","text":"<p>Retrieve all Jobs from the Slurm controller</p> <p>Parameters:</p> Name Type Description Default <code>preload_passwd_info</code> <code>bool</code> <p>Decides whether to query passwd and groups information from the system. Could potentially speed up access to attributes of the Job where a UID/GID is translated to a name. If True, the information will fetched and stored in each of the Job instances.</p> <code>False</code> <code>frozen</code> <code>bool</code> <p>Decide whether this collection of Jobs should be frozen.</p> <code>False</code> <p>Returns:</p> Type Description <code>Jobs</code> <p>A collection of Job objects.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When getting all the Jobs from the slurmctld failed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; jobs = pyslurm.Jobs.load()\n&gt;&gt;&gt; print(jobs)\npyslurm.Jobs({1: pyslurm.Job(1), 2: pyslurm.Job(2)})\n&gt;&gt;&gt; print(jobs[1])\npyslurm.Job(1)\n</code></pre>"},{"location":"reference/job/#pyslurm.Jobs.load_stats","title":"<code>load_stats()</code>  <code>method descriptor</code>","text":"<p>Load realtime stats for this collection of Jobs.</p> <p>This function additionally fills in the <code>stats</code> attribute for all Jobs in the collection, and also populates its own <code>stats</code> attribute. Implicitly calls <code>load_steps()</code>.</p> <p>Note</p> <p>Pending Jobs will be ignored, since they don't have any Stats yet.</p> <p>Returns:</p> Type Description <code>JobStatistics</code> <p>The statistics of this job collection.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When retrieving the stats for all the Jobs failed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; jobs = pyslurm.Jobs.load()\n&gt;&gt;&gt; stats = jobs.load_stats()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Print the CPU Time Used\n&gt;&gt;&gt; print(stats.total_cpu_time)\n</code></pre>"},{"location":"reference/job/#pyslurm.Jobs.load_steps","title":"<code>load_steps()</code>  <code>method descriptor</code>","text":"<p>Load all Job steps for this collection of Jobs.</p> <p>This function fills in the <code>steps</code> attribute for all Jobs in the collection.</p> <p>Note</p> <p>Pending Jobs will be ignored, since they don't have any Steps yet.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When retrieving the information for all the Steps failed.</p>"},{"location":"reference/job/#pyslurm.Jobs.reload","title":"<code>reload()</code>  <code>method descriptor</code>","text":"<p>Reload the information for jobs in a collection.</p> <p>Returns:</p> Type Description <code>Jobs</code> <p>Returns self</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When getting the Jobs from the slurmctld failed.</p>"},{"location":"reference/jobstep/","title":"JobStep","text":"<p>Note</p> <p>This supersedes the pyslurm.jobstep class, which will be removed in a future release</p>"},{"location":"reference/jobstep/#pyslurm.JobStep","title":"<code>pyslurm.JobStep</code>","text":"<p>A Slurm Jobstep</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>Union[Job, int]</code> <p>The Job this Step belongs to.</p> <code>0</code> <code>step_id</code> <code>Union[int, str]</code> <p>Step-ID for this JobStep object.</p> <code>0</code> <p>Other Parameters:</p> Name Type Description <code>time_limit</code> <code>int</code> <p>Time limit in Minutes for this step.</p> <p>Attributes:</p> Name Type Description <code>stats</code> <code>JobStepStatistics</code> <p>Real-time statistics of a Step. Before you can access the stats data for a Step, you have to call the <code>load_stats</code> method of a Step instance or the Jobs collection.</p> <code>pids</code> <code>dict[str, list]</code> <p>Current Process-IDs of the Step, organized by node name. Before you can access the pids data, you have to call the <code>load_stats</code> method of a Srep instance or the Jobs collection.</p> <code>id</code> <code>Union[str, int]</code> <p>The id for this step.</p> <code>job_id</code> <code>int</code> <p>The id for the Job this step belongs to.</p> <code>name</code> <code>str</code> <p>Name of the step.</p> <code>user_id</code> <code>int</code> <p>User ID who owns this step.</p> <code>user_name</code> <code>str</code> <p>Name of the User who owns this step.</p> <code>time_limit</code> <code>int</code> <p>Time limit in Minutes for this step.</p> <code>network</code> <code>str</code> <p>Network specification for the step.</p> <code>cpu_frequency_min</code> <code>Union[str, int]</code> <p>Minimum CPU-Frequency requested.</p> <code>cpu_frequency_max</code> <code>Union[str, int]</code> <p>Maximum CPU-Frequency requested.</p> <code>cpu_frequency_governor</code> <code>Union[str, int]</code> <p>CPU-Frequency Governor requested.</p> <code>reserved_ports</code> <code>str</code> <p>Reserved ports for the step.</p> <code>cluster</code> <code>str</code> <p>Name of the cluster this step runs on.</p> <code>srun_host</code> <code>str</code> <p>Name of the host srun was executed on.</p> <code>srun_process_id</code> <code>int</code> <p>Process ID of the srun command.</p> <code>container</code> <code>str</code> <p>Path to the container OCI.</p> <code>allocated_nodes</code> <code>str</code> <p>Nodes the Job is using.</p> <code>start_time</code> <code>int</code> <p>Time this step started, as unix timestamp.</p> <code>run_time</code> <code>int</code> <p>Seconds this step has been running for.</p> <code>run_time_remaining</code> <code>int</code> <p>The amount of seconds the step has still left until hitting the <code>time_limit</code>.</p> <code>elapsed_cpu_time</code> <code>int</code> <p>Amount of CPU-Time used by the step so far. This is the result of multiplying the <code>run_time</code> with the amount of <code>cpus</code> allocated.</p> <code>partition</code> <code>str</code> <p>Name of the partition this step runs in.</p> <code>state</code> <code>str</code> <p>State the step is in.</p> <code>cpus</code> <code>int</code> <p>Number of CPUs this step uses in total.</p> <code>ntasks</code> <code>int</code> <p>Number of tasks this step uses.</p> <code>distribution</code> <code>dict</code> <p>Task distribution specification for the step.</p> <code>command</code> <code>str</code> <p>Command that was specified with srun.</p> <code>slurm_protocol_version</code> <code>int</code> <p>Slurm protocol version in use.</p>"},{"location":"reference/jobstep/#pyslurm.JobStep.cancel","title":"<code>cancel()</code>  <code>method descriptor</code>","text":"<p>Cancel a Job step.</p> <p>Implements the slurm_kill_job_step RPC.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When cancelling the Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; pyslurm.JobStep(9999, 1).cancel()\n</code></pre>"},{"location":"reference/jobstep/#pyslurm.JobStep.load","title":"<code>load(job_id, step_id)</code>  <code>staticmethod</code>","text":"<p>Load information for a specific job step.</p> <p>Implements the slurm_get_job_steps RPC.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>Union[Job, int]</code> <p>ID of the Job the Step belongs to.</p> required <code>step_id</code> <code>Union[int, str]</code> <p>Step-ID for the Step to be loaded.</p> required <p>Returns:</p> Type Description <code>JobStep</code> <p>Returns a new JobStep instance</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When retrieving Step information from the slurmctld was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; jobstep = pyslurm.JobStep.load(9999, 1)\n</code></pre>"},{"location":"reference/jobstep/#pyslurm.JobStep.load_stats","title":"<code>load_stats()</code>  <code>method descriptor</code>","text":"<p>Load realtime stats for this Step.</p> <p>Calling this function returns the live statistics of the step, and additionally populates the <code>stats</code> and <code>pids</code> attribute of the instance.</p> <p>Returns:</p> Type Description <code>JobStepStatistics</code> <p>The statistics of the Step.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When retrieving the stats for the Step failed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; step = pyslurm.JobStep.load(9999, 1)\n&gt;&gt;&gt; stats = step.load_stats()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Print the CPU Time Used\n&gt;&gt;&gt; print(stats.total_cpu_time)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Print the Process-IDs for the Step, organized by hostname\n&gt;&gt;&gt; print(step.pids)\n</code></pre>"},{"location":"reference/jobstep/#pyslurm.JobStep.modify","title":"<code>modify(changes)</code>  <code>method descriptor</code>","text":"<p>Modify a job step.</p> <p>Implements the slurm_update_step RPC.</p> <p>Parameters:</p> Name Type Description Default <code>changes</code> <code>JobStep</code> <p>Another JobStep object that contains all the changes to apply. Check the <code>Other Parameters</code> of the JobStep class to see which properties can be modified.</p> required <p>Raises:</p> Type Description <code>RPCError</code> <p>When updating the JobStep was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Setting the new time-limit to 20 days\n&gt;&gt;&gt; changes = pyslurm.JobStep(time_limit=\"20-00:00:00\")\n&gt;&gt;&gt; pyslurm.JobStep(9999, 1).modify(changes)\n</code></pre>"},{"location":"reference/jobstep/#pyslurm.JobStep.send_signal","title":"<code>send_signal(signal)</code>  <code>method descriptor</code>","text":"<p>Send a signal to a running Job step.</p> <p>Implements the slurm_signal_job_step RPC.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>Union[str, int]</code> <p>Any valid signal which will be sent to the Job. Can be either a str like <code>SIGUSR1</code>, or simply an int.</p> required <p>Raises:</p> Type Description <code>RPCError</code> <p>When sending the signal was not successful.</p> <p>Examples:</p> <p>Specifying the signal as a string:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; pyslurm.JobStep(9999, 1).send_signal(\"SIGUSR1\")\n</code></pre> <p>or passing in a numeric signal:</p> <pre><code>&gt;&gt;&gt; pyslurm.JobStep(9999, 1).send_signal(9)\n</code></pre>"},{"location":"reference/jobstep/#pyslurm.JobStep.to_dict","title":"<code>to_dict()</code>  <code>method descriptor</code>","text":"<p>JobStep information formatted as a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>JobStep information as dict</p>"},{"location":"reference/jobstep/#pyslurm.JobSteps","title":"<code>pyslurm.JobSteps</code>","text":"<p>               Bases: <code>builtins.dict</code></p> <p>A dict of pyslurm.JobStep objects for a given Job.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When getting the Job steps from the slurmctld failed.</p>"},{"location":"reference/jobstep/#pyslurm.JobSteps.load","title":"<code>load(job)</code>  <code>staticmethod</code>","text":"<p>Load the Job Steps from the system.</p> <p>Parameters:</p> Name Type Description Default <code>job</code> <code>Union[Job, int]</code> <p>The Job for which the Steps should be loaded.</p> required <p>Returns:</p> Type Description <code>JobSteps</code> <p>JobSteps of the Job</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; steps = pyslurm.JobSteps.load(1)\n&gt;&gt;&gt; print(steps)\npyslurm.JobSteps({'batch': pyslurm.JobStep('batch')})\n&gt;&gt;&gt; print(steps[1])\npyslurm.JobStep('batch')\n</code></pre>"},{"location":"reference/jobstep/#pyslurm.JobSteps.load_all","title":"<code>load_all()</code>  <code>staticmethod</code>","text":"<p>Loads all the steps in the system.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dict where every JobID (key) is mapped with an instance of its JobSteps (value).</p>"},{"location":"reference/jobsubmitdescription/","title":"JobSubmitDescription","text":""},{"location":"reference/jobsubmitdescription/#pyslurm.JobSubmitDescription","title":"<code>pyslurm.JobSubmitDescription</code>","text":"<p>Submit Description for a Slurm Job.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Any valid Attribute this object has</p> required <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the Job, same as -J/--job-name from sbatch.</p> <code>account</code> <code>str</code> <p>Account of the job, same as -A/--account from sbatch.</p> <code>user_id</code> <code>Union[str, int]</code> <p>Run the job as a different User, same as --uid from sbatch. This requires root privileges. You can both specify the name or numeric uid of the User.</p> <code>group_id</code> <code>Union[str, int]</code> <p>Run the job as a different Group, same as --gid from sbatch. This requires root privileges. You can both specify the name or numeric gid of the User.</p> <code>priority</code> <code>int</code> <p>Specific priority the Job will receive. Same as --priority from sbatch. You can achieve the behaviour of sbatch's --hold option by specifying a priority of 0.</p> <code>site_factor</code> <code>int</code> <p>Site Factor of the Job. Only used when updating an existing Job.</p> <code>wckey</code> <code>str</code> <p>WCKey to use with the Job, same as --wckey from sbatch.</p> <code>array</code> <code>str</code> <p>Job Array specification, same as -a/--array from sbatch.</p> <code>batch_constraints</code> <code>str</code> <p>Batch Features of a Job, same as --batch from sbatch.</p> <code>begin_time</code> <code>str</code> <p>Defer allocation until the specified time, same as --begin from sbatch.</p> <code>clusters</code> <code>Union[list, str]</code> <p>Clusters the job may run on, same as -M/--clusters from sbatch.</p> <code>cluster_constraints</code> <code>str</code> <p>Comma-separated str with cluster constraints for the job. This is the same as --cluster-constraint from sbatch.</p> <code>comment</code> <code>str</code> <p>Arbitrary job comment, same as --comment from sbatch.</p> <code>admin_comment</code> <code>str</code> <p>Arbitrary job admin comment. Only used when updating an existing job.</p> <code>requires_contiguous_nodes</code> <code>bool</code> <p>Whether allocated Nodes are required to form a contiguous set. Same as --contiguous from sbatch.</p> <code>cores_reserved_for_system</code> <code>int</code> <p>Count of cores reserved for system not usable by the Job. Same as -S/--core-spec from sbatch. Mutually exclusive with <code>threads_reserved_for_system</code>.</p> <code>threads_reserved_for_system</code> <code>int</code> <p>Count of threads reserved for system not usable by the Job. Same as --thread-spec from sbatch. Mutually exclusive with <code>cores_reserved_for_system</code>.</p> <code>working_directory</code> <code>str</code> <p>Work directory for the Job. Default is current work-dir from where the job was submitted. Same as -D/--chdir from sbatch.</p> <code>cpu_frequency</code> <code>Union[dict, str]</code> <p>CPU Frequency for the Job, same as --cpu-freq from sbatch.</p> <p>For example, specifying it as a dict:</p> <pre><code>cpu_frequency = {\n    \"min\": \"Low\",\n    \"max\": \"High\",\n    \"governor\": \"UserSpace\"\n}\n</code></pre> <p>or like in sbatch with a string. For more info on that, check out the sbatch documentation for --cpu-freq.</p> <p>If you only want to set a Governor without any min or max, you can simply specify it as a standalone string:</p> <pre><code>cpu_frequency = \"Performance\"\nor\ncpu_frequency = {\"governor\": \"Performance\"}\n</code></pre> <p>If you want to set a specific, fixed frequency, you can do:</p> <pre><code>cpu_frequency = &lt;frequency in kilohertz&gt;\nor either\ncpu_frequency = {\"max\": &lt;freq&gt;} or cpu_freq = {\"min\": &lt;freq&gt;}\n</code></pre> <code>nodes</code> <code>Union[dict, str, int]</code> <p>Amount of nodes needed for the job. This is the same as -N/--nodes from sbatch.</p> <p>For example, providing min/max nodes as a dict:</p> <pre><code>nodes = {\n    \"min\": 3,\n    \"max\": 6\n}\n</code></pre> <p>When no range is needed, you can also simply specify it as int:</p> <pre><code>nodes = 3\n</code></pre> <p>Other than that, a range can also be specified in a str like with sbatch:</p> <pre><code>nodes = \"1-5\"\n</code></pre> <code>deadline</code> <code>str</code> <p>Deadline specification for the Job, same as --deadline from sbatch.</p> <code>delay_boot_time</code> <code>Union[str, int]</code> <p>Delay boot specification for the Job, same as --delay-boot from sbatch.</p> <code>dependencies</code> <code>Union[dict, str]</code> <p>Dependencies for the Job, same as -d/--dependency from sbatch.</p> <code>excluded_nodes</code> <code>Union[list, str]</code> <p>Exclude specific nodes for this Job. This is the same as -x/--exclude from sbatch.</p> <code>required_nodes</code> <code>Union[list, str]</code> <p>Specific list of nodes required for the Job. This is the same as -w/--nodelist from sbatch.</p> <code>constraints</code> <code>str</code> <p>Required node features for the Job. This is the same as -C/--constraint from sbatch.</p> <code>kill_on_node_fail</code> <code>bool</code> <p>Should the job get killed if one of the Nodes fails? This is the same as -k/--no-kill from sbatch.</p> <code>licenses</code> <code>Union[list, str]</code> <p>A list of licenses for the Job. This is the same as -L/--licenses from sbatch.</p> <code>mail_user</code> <code>Union[list, str]</code> <p>List of email addresses for notifications. This is the same as --mail-user from sbatch.</p> <code>mail_types</code> <code>Union[list, str]</code> <p>List of mail flags. This is the same as --mail-type from sbatch.</p> <code>mcs_label</code> <code>str</code> <p>An MCS Label for the Job. This is the same as --mcs-label from sbatch.</p> <code>memory_per_cpu</code> <code>Union[str, int]</code> <p>Memory required per allocated CPU.</p> <p>The default unit is in Mebibytes. You are also able to specify unit suffixes like K|M|G|T. This is the same as --mem-per-cpu from sbatch. This is mutually exclusive with memory_per_node and memory_per_gpu.</p> <p>Examples:</p> <pre><code># 1 MiB\nmemory_per_cpu = 1024\n\n# 3 GiB\nmemory_per_cpu = \"3G\"\n</code></pre> <code>memory_per_node</code> <code>Union[str, int]</code> <p>Memory required per whole node.</p> <p>The default unit is in Mebibytes. You are also able to specify unit suffixes like K|M|G|T. This is the same as --mem from sbatch. This is mutually exclusive with memory_per_cpu and memory_per_gpu.</p> <p>Examples:</p> <pre><code># 1 MiB\nmemory_per_node = 1024\n\n# 3 GiB\nmemory_per_node = \"3G\"\n</code></pre> <code>memory_per_gpu</code> <code>Union[str, int]</code> <p>Memory required per GPU.</p> <p>The default unit is in Mebibytes. You are also able to specify unit suffixes like K|M|G|T. This is the same as --mem-per-gpu from sbatch. This is mutually exclusive with memory_per_node and memory_per_cpu.</p> <p>Examples:</p> <pre><code># 1 MiB\nmemory_per_gpu = 1024\n\n# 3 GiB\nmemory_per_gpu = \"3G\"\n</code></pre> <code>network</code> <code>str</code> <p>Network types for the Job. This is the same as --network from sbatch.</p> <code>nice</code> <code>int</code> <p>Adjusted scheduling priority for the Job. This is the same as --nice from sbatch.</p> <code>log_files_open_mode</code> <code>str</code> <p>Mode in which standard_output and standard_error log files should be opened. This is the same as --open-mode from sbatch.</p> <p>Valid options are:</p> <ul> <li><code>append</code></li> <li><code>truncate</code></li> </ul> <code>overcommit</code> <code>bool</code> <p>If the resources should be overcommitted. This is the same as -O/--overcommit from sbatch.</p> <code>partitions</code> <code>Union[list, str]</code> <p>A list of partitions the Job may use. This is the same as -p/--partition from sbatch.</p> <code>accounting_gather_frequency</code> <code>Union[dict, str]</code> <p>Interval for accounting info to be gathered. This is the same as --acctg-freq from sbatch.</p> <p>For example, specifying it as a dict:</p> <pre><code>accounting_gather_frequency = {\n    \"energy\"=60,\n    \"network\"=20,\n}\n</code></pre> <p>or as a single string:</p> <pre><code>accounting_gather_frequency = \"energy=60,network=20\"\n</code></pre> <code>qos</code> <code>str</code> <p>Quality of Service for the Job. This is the same as -q/--qos from sbatch.</p> <code>requires_node_reboot</code> <code>bool</code> <p>Force the allocated nodes to reboot before the job starts. This is the same --reboot from sbatch.</p> <code>is_requeueable</code> <code>bool</code> <p>If the Job is eligible for requeuing. This is the same as --requeue from sbatch.</p> <code>reservations</code> <code>Union[list, str]</code> <p>A list of possible reservations the Job can use. This is the same as --reservation from sbatch.</p> <code>script</code> <code>str</code> <p>Absolute Path or content of the batch script.</p> <p>You can specify either a path to a script which will be loaded, or you can pass the script as a string. If the script is passed as a string, providing arguments to it (see <code>script_args</code>) is not supported.</p> <code>script_args</code> <code>str</code> <p>Arguments passed to the batch script. You can only set arguments if a file path was specified for <code>script</code>.</p> <code>environment</code> <code>Union[dict, str]</code> <p>Environment variables to be set for the Job. This is the same as --export from sbatch.</p> <code>resource_sharing</code> <code>str</code> <p>Controls the resource sharing with other Jobs. This property combines functionality of --oversubscribe and --exclusive from sbatch.</p> <p>Allowed values are are:</p> <ul> <li> <p><code>oversubscribe</code> or <code>yes</code>:</p> <p>The Job allows resources to be shared with other running Jobs.</p> </li> <li> <p><code>user</code>:</p> <p>Only sharing resources with other Jobs that have the \"user\" option set is allowed</p> </li> <li> <p><code>mcs</code>:</p> <p>Only sharing resources with other Jobs that have the \"mcs\" option set is allowed.</p> </li> <li> <p><code>no</code> or <code>exclusive</code>:</p> <p>No sharing of resources is allowed. (--exclusive from sbatch)</p> </li> </ul> <code>distribution</code> <code>str</code> <p>Task distribution for the Job, same as --distribution from sbatch</p> <code>time_limit</code> <code>str</code> <p>The time limit for the job. This is the same as -t/--time from sbatch.</p> <code>time_limit_min</code> <code>str</code> <p>A minimum time limit for the Job. This is the same as --time-min from sbatch.</p> <code>container</code> <code>str</code> <p>Path to an OCI container bundle. This is the same as --container from sbatch.</p> <code>cpus_per_task</code> <code>int</code> <p>The amount of cpus required for each task.</p> <p>This is the same as -c/--cpus-per-task from sbatch. This is mutually exclusive with <code>cpus_per_gpu</code>.</p> <code>cpus_per_gpu</code> <code>int</code> <p>The amount of cpus required for each allocated GPU.</p> <p>This is the same as --cpus-per-gpu from sbatch. This is mutually exclusive with <code>cpus_per_task</code>.</p> <code>sockets_per_node</code> <code>int</code> <p>Restrict Job to nodes with at least this many sockets. This is the same as --sockets-per-node from sbatch.</p> <code>cores_per_socket</code> <code>int</code> <p>Restrict Job to nodes with at least this many cores per socket This is the same as --cores-per-socket from sbatch.</p> <code>threads_per_core</code> <code>int</code> <p>Restrict Job to nodes with at least this many threads per socket This is the same as --threads-per-core from sbatch.</p> <code>gpus</code> <code>Union[dict, str, int]</code> <p>GPUs for the Job to be allocated in total. This is the same as -G/--gpus from sbatch. Specifying the type of the GPU is optional.</p> <p>For example, specifying the GPU counts as a dict:</p> <pre><code>gpus = {\n    \"tesla\": 1,\n    \"volta\": 5,\n}\n</code></pre> <p>Or, for example, in string format:</p> <pre><code>gpus = \"tesla:1,volta:5\"\n</code></pre> <p>Or, if you don't care about the type of the GPU:</p> <pre><code>gpus = 6\n</code></pre> <code>gpus_per_socket</code> <code>Union[dict, str, int]</code> <p>GPUs for the Job to be allocated per socket.</p> <p>This is the same as --gpus-per-socket from sbatch.</p> <p>Specifying the type of the GPU is optional. Note that setting <code>gpus_per_socket</code> requires to also specify sockets_per_node.</p> <p>For example, specifying it as a dict:</p> <pre><code>gpus_per_socket = {\n    \"tesla\": 1,\n    \"volta\": 5,\n}\n</code></pre> <p>Or, for example, in string format:</p> <pre><code>gpus_per_socket = \"tesla:1,volta:5\"\n</code></pre> <p>Or, if you don't care about the type of the GPU:</p> <pre><code>gpus_per_socket = 6\n</code></pre> <code>gpus_per_task</code> <code>Union[dict, str, int]</code> <p>GPUs for the Job to be allocated per task.</p> <p>This is the same as --gpus-per-task from sbatch.</p> <p>Specifying the type of the GPU is optional. Note that setting <code>gpus_per_task</code> requires to also specify either one of <code>ntasks</code> or <code>gpus</code>.</p> <p>For example, specifying it as a dict:</p> <pre><code>gpus_per_task = {\n    \"tesla\": 1,\n    \"volta\": 5,\n}\n</code></pre> <p>Or, for example, in string format:</p> <pre><code>gpus_per_task = \"tesla:1,volta:5\"\n</code></pre> <p>Or, if you don't care about the type of the GPU:</p> <pre><code>gpus_per_task = 6\n</code></pre> <code>gres_per_node</code> <code>Union[dict, str]</code> <p>Generic resources to be allocated per node.</p> <p>This is the same as --gres from sbatch. You should also use this option if you want to specify GPUs per node (--gpus-per-node). Specifying the type (by separating GRES name and type with a semicolon) is optional.</p> <p>For example, specifying it as a dict:</p> <pre><code>gres_per_node = {\n    \"gpu:tesla\": 1,\n    \"gpu:volta\": 5,\n}\n</code></pre> <p>Or, for example, in string format:</p> <pre><code>gres_per_node = \"gpu:tesla:1,gpu:volta:5\"\n</code></pre> <p>GPU Gres without a specific type:</p> <pre><code>gres_per_node = \"gpu:6\"\n</code></pre> <code>gpu_binding</code> <code>str</code> <p>Specify GPU binding for the Job. This is the same as --gpu-bind from sbatch.</p> <code>ntasks</code> <code>int</code> <p>Maximum amount of tasks for the Job. This is the same as -n/--ntasks from sbatch.</p> <code>ntasks_per_node</code> <code>int</code> <p>Amount of tasks to be invoked on each node. This is the same as --ntasks-per-node from sbatch.</p> <code>ntasks_per_socket</code> <code>int</code> <p>Maximum amount of tasks to be invoked on each socket. This is the same as --ntasks-per-socket from sbatch.</p> <code>ntasks_per_core</code> <code>int</code> <p>Maximum amount of tasks to be invoked on each core. This is the same as --ntasks-per-core from sbatch.</p> <code>ntasks_per_gpu</code> <code>int</code> <p>Amount of tasks to be invoked per GPU. This is the same as --ntasks-per-socket from sbatch.</p> <code>switches</code> <code>Union[dict, str, int]</code> <p>Maximum amount of leaf switches and wait time desired.</p> <p>This can also optionally include a maximum waiting time for these switches. This is the same as --switches from sbatch.</p> <p>For example, specifying it as a dict:</p> <pre><code>switches = { \"count\": 5, \"max_wait_time\": \"00:10:00\" }\n</code></pre> <p>Or as a single string (sbatch-style):</p> <pre><code>switches = \"5@00:10:00\"\n</code></pre> <code>signal</code> <code>Union[dict, str]</code> <p>Warn signal to be sent to the Job.</p> <p>This is the same as --signal from sbatch. The signal can both be specified with its name, e.g. \"SIGKILL\", or as a number, e.g. 9</p> <p>For example, specifying it as a dict:</p> <pre><code>signal = {\n    \"signal\": \"SIGKILL\",\n    \"time\": 120\n}\n</code></pre> <p>The above will send a \"SIGKILL\" signal 120 seconds before the Jobs' time limit is reached.</p> <p>Or, specifying it as a string (sbatch-style):</p> <pre><code>signal = \"SIGKILL@120\"\n</code></pre> <code>standard_in</code> <code>str</code> <p>Path to a File acting as standard_in for the batch-script. This is the same as -i/--input from sbatch.</p> <code>standard_error</code> <code>str</code> <p>Path to a File acting as standard_error for the batch-script. This is the same as -e/--error from sbatch.</p> <code>standard_output</code> <code>str</code> <p>Path to a File to write the Jobs standard_output. This is the same as -o/--output from sbatch.</p> <code>kill_on_invalid_dependency</code> <code>bool</code> <p>Kill the job if it has an invalid dependency. This is the same as --kill-on-invalid-dep from sbatch.</p> <code>spreads_over_nodes</code> <code>bool</code> <p>Spread the Job over as many nodes as possible. This is the same as --spread-job from sbatch.</p> <code>use_min_nodes</code> <code>bool</code> <p>Prefer the minimum amount of nodes specified. This is the same as --use-min-nodes from sbatch.</p> <code>gres_binding</code> <code>str</code> <p>Generic resource task binding options. This is contained in the --gres-flags option from sbatch.</p> <p>Possible values are:</p> <ul> <li><code>enforce-binding</code></li> <li><code>disable-binding</code></li> </ul> <code>gres_tasks_per_sharing</code> <code>str</code> <p>Shared GRES Tasks This is contained in the --gres-flags option from sbatch.</p> <p>Possible values are:</p> <ul> <li><code>multiple</code> or <code>multiple-tasks-per-sharing</code></li> <li><code>one</code> or <code>one-task-per-sharing</code></li> </ul> <code>temporary_disk_per_node</code> <code>Union[str, int]</code> <p>Amount of temporary disk space needed per node.</p> <p>This is the same as --tmp from sbatch. You can specify units like K|M|G|T (multiples of 1024). If no unit is specified, the value will be assumed as Mebibytes.</p> <p>Examples:</p> <pre><code># 2048 MiB\ntmp_disk_per_node = \"2G\"\n\n# 1024 MiB\ntmp_disk_per_node = 1024\n</code></pre> <code>get_user_environment</code> <code>Union[str, bool, int]</code> <p>TODO</p> <code>min_cpus_per_node</code> <code>str</code> <p>Set the minimum amount of CPUs required per Node. This is the same as --mincpus from sbatch.</p> <code>wait_all_nodes</code> <code>bool</code> <p>Controls when the execution of the command begins.</p> <p>A value of True means that the Job should begin execution only after all nodes in the allocation are ready. Setting it to False, the default, means that it is not waited for the nodes to be ready. (i.e booted)</p>"},{"location":"reference/jobsubmitdescription/#pyslurm.JobSubmitDescription.load_environment","title":"<code>load_environment(overwrite=False)</code>  <code>method descriptor</code>","text":"<p>Load values of attributes provided through the environment.</p> <p>Note</p> <p>Instead of <code>SBATCH_</code>, pyslurm uses <code>PYSLURM_JOBDESC_</code> as a prefix to identify environment variables which should be used to set attributes.</p> <p>Parameters:</p> Name Type Description Default <code>overwrite</code> <code>bool</code> <p>If set to <code>True</code>, the value from an option found in the environment will override the current value of the attribute in this instance. Default is <code>False</code></p> <code>False</code> <p>Examples:</p> <p>Lets consider you want to set the name of the Job, its Account name and that the Job cannot be requeued. Therefore, you will need to have set these environment variables:</p> <pre><code># Format is: PYSLURM_JOBDESC_{ATTRIBUTE_NAME}\nexport PYSLURM_JOBDESC_ACCOUNT=\"myaccount\"\nexport PYSLURM_JOBDESC_NAME=\"myjobname\"\nexport PYSLURM_JOBDESC_IS_REQUEUEABLE=\"False\"\n</code></pre> <p>As you can see above, boolean values should be the literal strings \"False\" or \"True\". In python, you can do this now:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; desc = pyslurm.JobSubmitDescription(...other args...)\n&gt;&gt;&gt; desc.load_environment()\n&gt;&gt;&gt; print(desc.name, desc.account, desc.is_requeueable)\nmyjobname, myaccount, False\n</code></pre>"},{"location":"reference/jobsubmitdescription/#pyslurm.JobSubmitDescription.load_sbatch_options","title":"<code>load_sbatch_options(overwrite=False)</code>  <code>method descriptor</code>","text":"<p>Load values from <code>#SBATCH</code> options in the batch script.</p> <p>Parameters:</p> Name Type Description Default <code>overwrite</code> <code>bool</code> <p>If set to <code>True</code>, the value from an option found in the in the batch script will override the current value of the attribute in this instance. Default is <code>False</code></p> <code>False</code>"},{"location":"reference/jobsubmitdescription/#pyslurm.JobSubmitDescription.submit","title":"<code>submit()</code>  <code>method descriptor</code>","text":"<p>Submit a batch job description.</p> <p>Returns:</p> Type Description <code>int</code> <p>The ID of the submitted Job.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When the job submission was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; desc = pyslurm.JobSubmitDescription(\n...     name=\"test-job\",\n...     cpus_per_task=1,\n...     time_limit=\"10-00:00:00\",\n...     script=\"/path/to/your/submit_script.sh\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; job_id = desc.submit()\n&gt;&gt;&gt; print(job_id)\n99\n</code></pre>"},{"location":"reference/node/","title":"Node","text":"<p>Note</p> <p>This supersedes the pyslurm.node class, which will be removed in a future release</p>"},{"location":"reference/node/#pyslurm.Node","title":"<code>pyslurm.Node</code>","text":"<p>A Slurm node.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of a node</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>configured_gres</code> <code>dict</code> <p>Configured GRES for the node</p> <code>address</code> <code>str</code> <p>Address of the node</p> <code>hostname</code> <code>str</code> <p>Hostname of the node</p> <code>extra</code> <code>str</code> <p>Arbitrary extra string</p> <code>comment</code> <code>str</code> <p>Comment for the node</p> <code>weight</code> <code>int</code> <p>Weight associated to the node</p> <code>available_features</code> <code>list</code> <p>Available features for the node</p> <code>active_features</code> <code>list</code> <p>Active features for the node</p> <code>cpu_binding</code> <code>str</code> <p>Default CPU-Binding for the node</p> <code>state</code> <code>str</code> <p>State of the node</p> <code>reason</code> <code>str</code> <p>Reason for the Node, typically used along with updating the node state</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the node.</p> <code>architecture</code> <code>str</code> <p>Architecture of the node (e.g. x86_64)</p> <code>configured_gres</code> <code>dict</code> <p>Generic Resources this Node is configured with.</p> <code>owner</code> <code>str</code> <p>User that owns the Node.</p> <code>address</code> <code>str</code> <p>Address of the node.</p> <code>hostname</code> <code>str</code> <p>Hostname of the node.</p> <code>extra</code> <code>str</code> <p>Arbitrary string attached to the Node.</p> <code>reason</code> <code>str</code> <p>Reason why this node is in its current state.</p> <code>reason_user</code> <code>str</code> <p>Name of the User who set the reason.</p> <code>comment</code> <code>str</code> <p>Arbitrary node comment.</p> <code>bcast_address</code> <code>str</code> <p>Address of the node for sbcast.</p> <code>slurm_version</code> <code>str</code> <p>Version of slurm this node is running on.</p> <code>operating_system</code> <code>str</code> <p>Name of the operating system installed.</p> <code>allocated_gres</code> <code>dict</code> <p>Generic Resources currently in use on the node.</p> <code>mcs_label</code> <code>str</code> <p>MCS label for the node.</p> <code>allocated_memory</code> <code>int</code> <p>Memory in Mebibytes allocated on the node.</p> <code>real_memory</code> <code>int</code> <p>Real Memory in Mebibytes configured for this node.</p> <code>free_memory</code> <code>int</code> <p>Free Memory in Mebibytes on the node. Note that this means actual free memory as returned by the <code>free</code> command</p> <code>idle_memory</code> <code>int</code> <p>Idle Memory in Mebibytes on the node.</p> <code>memory_reserved_for_system</code> <code>int</code> <p>Memory in Mebibytes reserved for the System not usable by Jobs.</p> <code>temporary_disk</code> <code>int</code> <p>Amount of temporary disk space this node has, in Mebibytes.</p> <code>weight</code> <code>int</code> <p>Weight of the node in scheduling.</p> <code>effective_cpus</code> <code>int</code> <p>Number of effective CPUs the node has.</p> <code>total_cpus</code> <code>int</code> <p>Total amount of CPUs the node has.</p> <code>sockets</code> <code>int</code> <p>Number of sockets the node has.</p> <code>cores_reserved_for_system</code> <code>int</code> <p>Number of cores reserved for the System not usable by Jobs.</p> <code>boards</code> <code>int</code> <p>Number of boards the node has.</p> <code>cores_per_socket</code> <code>int</code> <p>Number of cores per socket configured for the node.</p> <code>threads_per_core</code> <code>int</code> <p>Number of threads per core configured for the node.</p> <code>available_features</code> <code>list</code> <p>List of features available on the node.</p> <code>active_features</code> <code>list</code> <p>List of features on the node.</p> <code>partitions</code> <code>list</code> <p>List of partitions this Node is part of.</p> <code>boot_time</code> <code>int</code> <p>Time the node has booted, as unix timestamp.</p> <code>slurmd_start_time</code> <code>int</code> <p>Time the slurmd has started on the Node, as unix timestamp.</p> <code>last_busy_time</code> <code>int</code> <p>Time this node was last busy, as unix timestamp.</p> <code>reason_time</code> <code>int</code> <p>Time the reason was set for the node, as unix timestamp.</p> <code>allocated_tres</code> <code>dict</code> <p>Currently allocated Trackable Resources</p> <code>allocated_cpus</code> <code>int</code> <p>Number of allocated CPUs on the node.</p> <code>idle_cpus</code> <code>int</code> <p>Number of idle CPUs.</p> <code>cpu_binding</code> <code>str</code> <p>Default CPU-Binding on the node.</p> <code>current_watts</code> <code>int</code> <p>Current amount of watts consumed on the node.</p> <code>avg_watts</code> <code>int</code> <p>Average amount of watts consumed on the node.</p> <code>state</code> <code>str</code> <p>State the node is currently in.</p> <code>next_state</code> <code>str</code> <p>Next state the node will be in.</p> <code>cpu_load</code> <code>float</code> <p>CPU Load on the Node.</p> <code>slurmd_port</code> <code>int</code> <p>Port the slurmd is listening on the node.</p>"},{"location":"reference/node/#pyslurm.Node.create","title":"<code>create(state='future')</code>  <code>method descriptor</code>","text":"<p>Create a node.</p> <p>Implements the slurm_create_node RPC.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>str</code> <p>An optional state the created Node should have. Allowed values are <code>future</code> and <code>cloud</code>. <code>future</code> is the default.</p> <code>'future'</code> <p>Returns:</p> Type Description <code>Node</code> <p>This function returns the current Node-instance object itself.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>If creating the Node was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; node = pyslurm.Node(\"testnode\").create()\n</code></pre>"},{"location":"reference/node/#pyslurm.Node.delete","title":"<code>delete()</code>  <code>method descriptor</code>","text":"<p>Delete a node.</p> <p>Implements the slurm_delete_node RPC.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>If deleting the Node was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; pyslurm.Node(\"localhost\").delete()\n</code></pre>"},{"location":"reference/node/#pyslurm.Node.load","title":"<code>load(name)</code>  <code>staticmethod</code>","text":"<p>Load information for a specific node.</p> <p>Implements the slurm_load_node_single RPC.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Node to load.</p> required <p>Returns:</p> Type Description <code>Node</code> <p>Returns a new Node instance.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>If requesting the Node information from the slurmctld was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; node = pyslurm.Node.load(\"localhost\")\n</code></pre>"},{"location":"reference/node/#pyslurm.Node.modify","title":"<code>modify(changes)</code>  <code>method descriptor</code>","text":"<p>Modify a node.</p> <p>Implements the slurm_update_node RPC.</p> <p>Parameters:</p> Name Type Description Default <code>changes</code> <code>Node</code> <p>Another Node object that contains all the changes to apply. Check the <code>Other Parameters</code> of the Node class to see which properties can be modified.</p> required <p>Raises:</p> Type Description <code>RPCError</code> <p>When updating the Node was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt;\n&gt;&gt;&gt; mynode = pyslurm.Node.load(\"localhost\")\n&gt;&gt;&gt; # Prepare the changes\n&gt;&gt;&gt; changes = pyslurm.Node(state=\"DRAIN\", reason=\"DRAIN Reason\")\n&gt;&gt;&gt; # Modify it\n&gt;&gt;&gt; mynode.modify(changes)\n</code></pre>"},{"location":"reference/node/#pyslurm.Node.to_dict","title":"<code>to_dict()</code>  <code>method descriptor</code>","text":"<p>Node information formatted as a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Node information as dict</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; mynode = pyslurm.Node.load(\"mynode\")\n&gt;&gt;&gt; mynode_dict = mynode.to_dict()\n</code></pre>"},{"location":"reference/node/#pyslurm.Nodes","title":"<code>pyslurm.Nodes</code>","text":"<p>               Bases: <code>pyslurm.xcollections.MultiClusterMap</code></p> <p>A <code>Multi Cluster</code> collection of pyslurm.Node objects.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>Union[list[str], dict[str, Node], str]</code> <p>Nodes to initialize this collection with.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>free_memory</code> <code>int</code> <p>Amount of free memory in this node collection. (in Mebibytes) Note that this means actual free memory as returned by the <code>free</code> command</p> <code>real_memory</code> <code>int</code> <p>Amount of real memory in this node collection. (in Mebibytes)</p> <code>idle_memory</code> <code>int</code> <p>Amount of idle memory in this node collection. (in Mebibytes)</p> <code>allocated_memory</code> <code>int</code> <p>Amount of alloc Memory in this node collection. (in Mebibytes)</p> <code>total_cpus</code> <code>int</code> <p>Total amount of CPUs in this node collection.</p> <code>idle_cpus</code> <code>int</code> <p>Total amount of idle CPUs in this node collection.</p> <code>allocated_cpus</code> <code>int</code> <p>Total amount of allocated CPUs in this node collection.</p> <code>effective_cpus</code> <code>int</code> <p>Total amount of effective CPUs in this node collection.</p> <code>current_watts</code> <code>int</code> <p>Total amount of Watts consumed in this node collection.</p> <code>avg_watts</code> <code>int</code> <p>Amount of average watts consumed in this node collection.</p>"},{"location":"reference/node/#pyslurm.Nodes.load","title":"<code>load(preload_passwd_info=False)</code>  <code>staticmethod</code>","text":"<p>Load all nodes in the system.</p> <p>Parameters:</p> Name Type Description Default <code>preload_passwd_info</code> <code>bool</code> <p>Decides whether to query passwd and groups information from the system. Could potentially speed up access to attributes of the Node where a UID/GID is translated to a name. If True, the information will fetched and stored in each of the Node instances. The default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Nodes</code> <p>Collection of node objects.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When getting all the Nodes from the slurmctld failed.</p>"},{"location":"reference/node/#pyslurm.Nodes.modify","title":"<code>modify(changes)</code>  <code>method descriptor</code>","text":"<p>Modify all Nodes in a collection.</p> <p>Parameters:</p> Name Type Description Default <code>changes</code> <code>Node</code> <p>Another Node object that contains all the changes to apply. Check the <code>Other Parameters</code> of the Node class to see which properties can be modified.</p> required <p>Raises:</p> Type Description <code>RPCError</code> <p>When updating the Node was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt;\n&gt;&gt;&gt; nodes = pyslurm.Nodes.load()\n&gt;&gt;&gt; # Prepare the changes\n&gt;&gt;&gt; changes = pyslurm.Node(state=\"DRAIN\", reason=\"DRAIN Reason\")\n&gt;&gt;&gt; # Apply the changes to all the nodes\n&gt;&gt;&gt; nodes.modify(changes)\n</code></pre>"},{"location":"reference/node/#pyslurm.Nodes.reload","title":"<code>reload()</code>  <code>method descriptor</code>","text":"<p>Reload the information for Nodes in a collection.</p> <p>Note</p> <p>Only information for nodes which are already in the collection at the time of calling this method will be reloaded.</p> <p>Returns:</p> Type Description <code>Nodes</code> <p>Returns self</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When getting the Nodes from the slurmctld failed.</p>"},{"location":"reference/partition/","title":"Partition","text":"<p>Note</p> <p>This supersedes the pyslurm.partition class, which will be removed in a future release</p>"},{"location":"reference/partition/#pyslurm.Partition","title":"<code>pyslurm.Partition</code>","text":"<p>A Slurm partition.</p> Setting Memory related attributes <p>Unless otherwise noted, all attributes in this class representing a memory value, like <code>default_memory_per_cpu</code>, may also be set with a string that contains suffixes like \"K\", \"M\", \"G\" or \"T\".</p> <p>For example:</p> <pre><code>default_memory_per_cpu = \"10G\"\n</code></pre> <p>This will internally be converted to 10240 (how the Slurm API expects it)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of a Partition</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Every attribute of a Partition can be set, except for:</p> <ul> <li>total_cpus</li> <li>total_nodes</li> <li>select_type_parameters</li> </ul> required <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the Partition.</p> <code>allowed_submit_nodes</code> <code>list[str]</code> <p>List of Nodes from which Jobs can be submitted to the partition.</p> <code>allowed_accounts</code> <code>list[str]</code> <p>List of Accounts which are allowed to execute Jobs</p> <code>allowed_groups</code> <code>list[str]</code> <p>List of Groups which are allowed to execute Jobs</p> <code>allowed_qos</code> <code>list[str]</code> <p>List of QoS which are allowed to execute Jobs</p> <code>alternate</code> <code>str</code> <p>Name of the alternate Partition in case a Partition is down.</p> <code>select_type_parameters</code> <code>list[str]</code> <p>List of Select type parameters for the select plugin.</p> <code>cpu_binding</code> <code>str</code> <p>Default CPU-binding for Jobs that execute in a Partition.</p> <code>default_memory_per_cpu</code> <code>int</code> <p>Default Memory per CPU for Jobs in this Partition, in Mebibytes. Mutually exclusive with <code>default_memory_per_node</code>.</p> <p>This can also return UNLIMITED</p> <code>default_memory_per_node</code> <code>int</code> <p>Default Memory per Node for Jobs in this Partition, in Mebibytes. Mutually exclusive with <code>default_memory_per_cpu</code>.</p> <p>This can also return UNLIMITED</p> <code>max_memory_per_cpu</code> <code>int</code> <p>Max Memory per CPU allowed for Jobs in this Partition, in Mebibytes. Mutually exclusive with <code>max_memory_per_node</code>.</p> <p>This can also return UNLIMITED</p> <code>max_memory_per_node</code> <code>int</code> <p>Max Memory per Node allowed for Jobs in this Partition, in Mebibytes. Mutually exclusive with <code>max_memory_per_cpu</code></p> <p>This can also return UNLIMITED</p> <code>default_time</code> <code>int</code> <p>Default run time-limit in minutes for Jobs that don't specify one.</p> <p>This can also return UNLIMITED</p> <code>denied_qos</code> <code>list[str]</code> <p>List of QoS that cannot be used in a Partition</p> <code>denied_accounts</code> <code>list[str]</code> <p>List of Accounts that cannot use a Partition</p> <code>preemption_grace_time</code> <code>int</code> <p>Grace Time in seconds when a Job is selected for Preemption.</p> <code>default_cpus_per_gpu</code> <code>int</code> <p>Default CPUs per GPU for Jobs in this Partition</p> <code>default_memory_per_gpu</code> <code>int</code> <p>Default Memory per GPU, in Mebibytes, for Jobs in this Partition</p> <code>max_cpus_per_node</code> <code>int</code> <p>Max CPUs per Node allowed for Jobs in this Partition</p> <p>This can also return UNLIMITED</p> <code>max_cpus_per_socket</code> <code>int</code> <p>Max CPUs per Socket allowed for Jobs in this Partition</p> <p>This can also return UNLIMITED</p> <code>max_nodes</code> <code>int</code> <p>Max number of Nodes allowed for Jobs</p> <p>This can also return UNLIMITED</p> <code>min_nodes</code> <code>int</code> <p>Minimum number of Nodes that must be requested by Jobs</p> <code>max_time</code> <code>int</code> <p>Max Time-Limit in minutes that Jobs can request</p> <p>This can also return UNLIMITED</p> <code>oversubscribe</code> <code>str</code> <p>The oversubscribe mode for this Partition</p> <code>nodes</code> <code>str</code> <p>Nodes that are in a Partition</p> <code>nodesets</code> <code>list[str]</code> <p>List of Nodesets that a Partition has configured</p> <code>over_time_limit</code> <code>int</code> <p>Limit in minutes that Jobs can exceed their time-limit</p> <p>This can also return UNLIMITED</p> <code>preempt_mode</code> <code>str</code> <p>Preemption Mode in a Partition</p> <code>priority_job_factor</code> <code>int</code> <p>The Priority Job Factor for a partition</p> <code>priority_tier</code> <code>int</code> <p>The priority tier for a Partition</p> <code>qos</code> <code>str</code> <p>A QoS associated with a Partition, used to extend possible limits</p> <code>total_cpus</code> <code>int</code> <p>Total number of CPUs available in a Partition</p> <code>total_nodes</code> <code>int</code> <p>Total number of nodes available in a Partition</p> <code>state</code> <code>str</code> <p>State the Partition is in</p> <code>is_default</code> <code>bool</code> <p>Whether this Partition is the default partition or not</p> <code>allow_root_jobs</code> <code>bool</code> <p>Whether Jobs by the root user are allowed</p> <code>is_user_exclusive</code> <code>bool</code> <p>Whether nodes will be exclusively allocated to users</p> <code>is_hidden</code> <code>bool</code> <p>Whether the partition is hidden or not</p> <code>least_loaded_nodes_scheduling</code> <code>bool</code> <p>Whether Least-Loaded-Nodes scheduling algorithm is used on a Partition</p> <code>is_root_only</code> <code>bool</code> <p>Whether only root is able to use a Partition</p> <code>requires_reservation</code> <code>bool</code> <p>Whether a reservation is required to use a Partition</p> <code>power_down_on_idle</code> <code>bool</code> <p>Whether nodes power down on idle after running jobs</p>"},{"location":"reference/partition/#pyslurm.Partition.create","title":"<code>create()</code>  <code>method descriptor</code>","text":"<p>Create a Partition.</p> <p>Implements the slurm_create_partition RPC.</p> <p>Returns:</p> Type Description <code>Partition</code> <p>This function returns the current Partition instance object itself.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>If creating the Partition was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; part = pyslurm.Partition(\"debug\").create()\n</code></pre>"},{"location":"reference/partition/#pyslurm.Partition.delete","title":"<code>delete()</code>  <code>method descriptor</code>","text":"<p>Delete a Partition.</p> <p>Implements the slurm_delete_partition RPC.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When deleting the Partition was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; pyslurm.Partition(\"normal\").delete()\n</code></pre>"},{"location":"reference/partition/#pyslurm.Partition.load","title":"<code>load(name)</code>  <code>staticmethod</code>","text":"<p>Load information for a specific Partition.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the Partition to load.</p> required <p>Returns:</p> Type Description <code>Partition</code> <p>Returns a new Partition instance.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>If requesting the Partition information from the slurmctld was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; part = pyslurm.Partition.load(\"normal\")\n</code></pre>"},{"location":"reference/partition/#pyslurm.Partition.modify","title":"<code>modify(changes)</code>  <code>method descriptor</code>","text":"<p>Modify a Partition.</p> <p>Implements the slurm_update_partition RPC.</p> <p>Parameters:</p> Name Type Description Default <code>changes</code> <code>Partition</code> <p>Another Partition object that contains all the changes to apply. Check the <code>Other Parameters</code> of the Partition class to see which properties can be modified.</p> required <p>Raises:</p> Type Description <code>RPCError</code> <p>When updating the Partition was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt;\n&gt;&gt;&gt; part = pyslurm.Partition.load(\"normal\")\n&gt;&gt;&gt; # Prepare the changes\n&gt;&gt;&gt; changes = pyslurm.Partition(state=\"DRAIN\")\n&gt;&gt;&gt; # Apply the changes to the \"normal\" Partition\n&gt;&gt;&gt; part.modify(changes)\n</code></pre>"},{"location":"reference/partition/#pyslurm.Partition.to_dict","title":"<code>to_dict()</code>  <code>method descriptor</code>","text":"<p>Partition information formatted as a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Partition information as dict</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; mypart = pyslurm.Partition.load(\"mypart\")\n&gt;&gt;&gt; mypart_dict = mypart.to_dict()\n</code></pre>"},{"location":"reference/partition/#pyslurm.Partitions","title":"<code>pyslurm.Partitions</code>","text":"<p>               Bases: <code>pyslurm.xcollections.MultiClusterMap</code></p> <p>A <code>Multi Cluster</code> collection of pyslurm.Partition objects.</p> <p>Parameters:</p> Name Type Description Default <code>partitions</code> <code>Union[list[str], dict[str, Partition], str]</code> <p>Partitions to initialize this collection with.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>total_cpus</code> <code>int</code> <p>Total amount of CPUs the Partitions in a Collection have</p> <code>total_nodes</code> <code>int</code> <p>Total amount of Nodes the Partitions in a Collection have</p>"},{"location":"reference/partition/#pyslurm.Partitions.load","title":"<code>load()</code>  <code>staticmethod</code>","text":"<p>Load all Partitions in the system.</p> <p>Returns:</p> Type Description <code>Partitions</code> <p>Collection of Partition objects.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When getting all the Partitions from the slurmctld failed.</p>"},{"location":"reference/partition/#pyslurm.Partitions.modify","title":"<code>modify(changes)</code>  <code>method descriptor</code>","text":"<p>Modify all Partitions in a Collection.</p> <p>Parameters:</p> Name Type Description Default <code>changes</code> <code>Partition</code> <p>Another Partition object that contains all the changes to apply. Check the <code>Other Parameters</code> of the Partition class to see which properties can be modified.</p> required <p>Raises:</p> Type Description <code>RPCError</code> <p>When updating at least one Partition failed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt;\n&gt;&gt;&gt; parts = pyslurm.Partitions.load()\n&gt;&gt;&gt; # Prepare the changes\n&gt;&gt;&gt; changes = pyslurm.Partition(state=\"DRAIN\")\n&gt;&gt;&gt; # Apply the changes to all the partitions\n&gt;&gt;&gt; parts.modify(changes)\n</code></pre>"},{"location":"reference/partition/#pyslurm.Partitions.reload","title":"<code>reload()</code>  <code>method descriptor</code>","text":"<p>Reload the information for Partitions in a collection.</p> <p>Note</p> <p>Only information for Partitions which are already in the collection at the time of calling this method will be reloaded.</p> <p>Returns:</p> Type Description <code>Partitions</code> <p>Returns self</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When getting the Partitions from the slurmctld failed.</p>"},{"location":"reference/reservation/","title":"Reservation","text":"<p>Warning</p> <p>This API is currently being completely reworked, and is subject to be removed in the future when a replacement is introduced</p>"},{"location":"reference/reservation/#pyslurm.deprecated.reservation","title":"<code>pyslurm.deprecated.reservation</code>","text":"<p>Access/update/delete slurm reservation Information.</p>"},{"location":"reference/reservation/#pyslurm.deprecated.reservation.create","title":"<code>create(reservation_dict={})</code>  <code>method descriptor</code>","text":"<p>Create slurm reservation.</p> <p>Parameters:</p> Name Type Description Default <code>reservation_dict</code> <code>dict</code> <p>Reservation information</p> <code>{}</code> <p>Returns:</p> Type Description <code>int</code> <p>0 for success or a slurm error code</p>"},{"location":"reference/reservation/#pyslurm.deprecated.reservation.delete","title":"<code>delete(ResID)</code>  <code>method descriptor</code>","text":"<p>Delete slurm reservation.</p> <p>Parameters:</p> Name Type Description Default <code>ResID</code> <code>int</code> <p>ID of the reservation to delete</p> required <p>Returns:</p> Type Description <code>int</code> <p>0 for success or a slurm error code</p>"},{"location":"reference/reservation/#pyslurm.deprecated.reservation.find","title":"<code>find(name='', val='')</code>  <code>method descriptor</code>","text":"<p>Search for property and associated value in reservation data.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>key string to search</p> <code>''</code> <code>val</code> <code>str</code> <p>value string to match</p> <code>''</code> <p>Returns:</p> Type Description <code>list</code> <p>List of IDs that match</p>"},{"location":"reference/reservation/#pyslurm.deprecated.reservation.find_id","title":"<code>find_id(resID)</code>  <code>method descriptor</code>","text":"<p>Retrieve reservation ID data.</p> <p>Parameters:</p> Name Type Description Default <code>resID</code> <code>str</code> <p>Reservation key string to search</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of values for given reservation key</p>"},{"location":"reference/reservation/#pyslurm.deprecated.reservation.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get slurm reservation information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Data whose key is the Reservation ID</p>"},{"location":"reference/reservation/#pyslurm.deprecated.reservation.ids","title":"<code>ids()</code>  <code>method descriptor</code>","text":"<p>Return a list of reservation IDs from retrieved data.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of reservation IDs</p>"},{"location":"reference/reservation/#pyslurm.deprecated.reservation.lastUpdate","title":"<code>lastUpdate()</code>  <code>method descriptor</code>","text":"<p>Get the time (epoch seconds) the reservation data was updated.</p> <p>Returns:</p> Type Description <code>int</code> <p>epoch seconds</p>"},{"location":"reference/reservation/#pyslurm.deprecated.reservation.print_reservation_info_msg","title":"<code>print_reservation_info_msg(oneLiner=0)</code>  <code>method descriptor</code>","text":"<p>Output information about all slurm reservations.</p> <p>Parameters:</p> Name Type Description Default <code>oneLiner</code> <code>int</code> <p>Print reservation info in one-line</p> <code>0</code>"},{"location":"reference/reservation/#pyslurm.deprecated.reservation.update","title":"<code>update(reservation_dict={})</code>  <code>method descriptor</code>","text":"<p>Update a slurm reservation attributes.</p> <p>Parameters:</p> Name Type Description Default <code>reservation_dict</code> <code>dict</code> <p>Reservation information</p> <code>{}</code> <p>Returns:</p> Type Description <code>int</code> <p>0 for success or -1 for error and slurm error code is set</p>"},{"location":"reference/statistics/","title":"Statistics","text":"<p>Warning</p> <p>This API is currently being completely reworked, and is subject to be removed in the future when a replacement is introduced</p>"},{"location":"reference/statistics/#pyslurm.deprecated.statistics","title":"<code>pyslurm.deprecated.statistics</code>","text":"<p>Slurm Controller statistics.</p>"},{"location":"reference/statistics/#pyslurm.deprecated.statistics.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get slurm statistics information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Slurm Controller statistics</p>"},{"location":"reference/statistics/#pyslurm.deprecated.statistics.reset","title":"<code>reset()</code>  <code>method descriptor</code>","text":"<p>Reset scheduling statistics</p> <p>This method requires root privileges.</p>"},{"location":"reference/topology/","title":"Topology","text":"<p>Warning</p> <p>This API is currently being completely reworked, and is subject to be removed in the future when a replacement is introduced</p>"},{"location":"reference/topology/#pyslurm.deprecated.topology","title":"<code>pyslurm.deprecated.topology</code>","text":"<p>Access/update slurm topology information.</p>"},{"location":"reference/topology/#pyslurm.deprecated.topology.display","title":"<code>display()</code>  <code>method descriptor</code>","text":"<p>Display topology information to standard output.</p>"},{"location":"reference/topology/#pyslurm.deprecated.topology.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get slurm topology information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary whose key is the Topology ID</p>"},{"location":"reference/topology/#pyslurm.deprecated.topology.lastUpdate","title":"<code>lastUpdate()</code>  <code>method descriptor</code>","text":"<p>Get the time (epoch seconds) the retrieved data was updated.</p> <p>Returns:</p> Type Description <code>int</code> <p>Epoch seconds</p>"},{"location":"reference/topology/#pyslurm.deprecated.topology.load","title":"<code>load()</code>  <code>method descriptor</code>","text":"<p>Load slurm topology information.</p>"},{"location":"reference/trigger/","title":"Trigger","text":"<p>Warning</p> <p>This API is currently being completely reworked, and is subject to be removed in the future when a replacement is introduced</p>"},{"location":"reference/trigger/#pyslurm.deprecated.trigger","title":"<code>pyslurm.deprecated.trigger</code>","text":""},{"location":"reference/trigger/#pyslurm.deprecated.trigger.clear","title":"<code>clear(TriggerID=0, UserID=4294967294, ID=0)</code>  <code>method descriptor</code>","text":"<p>Clear or remove a slurm trigger.</p> <p>Parameters:</p> Name Type Description Default <code>TriggerID</code> <code>str</code> <p>Trigger Identifier</p> <code>0</code> <code>UserID</code> <code>str</code> <p>User Identifier</p> <code>4294967294</code> <code>ID</code> <code>str</code> <p>Job Identifier</p> <code>0</code> <p>Returns:</p> Type Description <code>int</code> <p>0 for success or a slurm error code</p>"},{"location":"reference/trigger/#pyslurm.deprecated.trigger.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get the information on slurm triggers.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary, where keys are the trigger IDs</p>"},{"location":"reference/trigger/#pyslurm.deprecated.trigger.set","title":"<code>set(trigger_dict)</code>  <code>method descriptor</code>","text":"<p>Set or create a slurm trigger.</p> <p>Parameters:</p> Name Type Description Default <code>trigger_dict</code> <code>dict</code> <p>A populated dictionary of trigger information</p> required <p>Returns:</p> Type Description <code>int</code> <p>0 for success or -1 for error, and the slurm error code is set appropriately.</p>"},{"location":"reference/utilities/","title":"utils","text":""},{"location":"reference/utilities/#pyslurm.utils","title":"<code>pyslurm.utils</code>","text":"<p>pyslurm utility functions</p>"},{"location":"reference/utilities/#pyslurm.utils.timestr_to_secs","title":"<code>pyslurm.utils.timestr_to_secs(timestr)</code>  <code>method descriptor</code>","text":"<p>Convert Slurm Timestring to seconds</p> <p>Parameters:</p> Name Type Description Default <code>timestr</code> <code>str</code> <p>A Timestring compatible with Slurms time functions.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Amount of time in seconds</p>"},{"location":"reference/utilities/#pyslurm.utils.timestr_to_mins","title":"<code>pyslurm.utils.timestr_to_mins(timestr)</code>  <code>method descriptor</code>","text":"<p>Convert Slurm Timestring to minutes</p> <p>Parameters:</p> Name Type Description Default <code>timestr</code> <code>str</code> <p>A Timestring compatible with Slurms time functions.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Amount of time in minutes</p>"},{"location":"reference/utilities/#pyslurm.utils.secs_to_timestr","title":"<code>pyslurm.utils.secs_to_timestr(secs, default=None)</code>  <code>method descriptor</code>","text":"<p>Parse time in seconds to Slurm Timestring</p> <p>Parameters:</p> Name Type Description Default <code>secs</code> <code>int</code> <p>Amount of seconds to convert </p> required <p>Returns:</p> Type Description <code>str</code> <p>A Slurm timestring</p>"},{"location":"reference/utilities/#pyslurm.utils.mins_to_timestr","title":"<code>pyslurm.utils.mins_to_timestr(mins, default=None)</code>  <code>method descriptor</code>","text":"<p>Parse time in minutes to Slurm Timestring</p> <p>Parameters:</p> Name Type Description Default <code>mins</code> <code>int</code> <p>Amount of minutes to convert</p> required <p>Returns:</p> Type Description <code>str</code> <p>A Slurm timestring</p>"},{"location":"reference/utilities/#pyslurm.utils.date_to_timestamp","title":"<code>pyslurm.utils.date_to_timestamp(date, on_nodate=0)</code>  <code>method descriptor</code>","text":"<p>Parse Date to Unix timestamp</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>Union[str, int, datetime]</code> <p>A date to convert to a Unix timestamp.</p> required <p>Returns:</p> Type Description <code>int</code> <p>A unix timestamp</p>"},{"location":"reference/utilities/#pyslurm.utils.timestamp_to_date","title":"<code>pyslurm.utils.timestamp_to_date(timestamp)</code>  <code>method descriptor</code>","text":"<p>Parse Unix timestamp to Slurm Date-string</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>int</code> <p>A Unix timestamp that should be converted.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A Slurm date timestring</p>"},{"location":"reference/utilities/#pyslurm.utils.expand_range_str","title":"<code>pyslurm.utils.expand_range_str(range_str)</code>  <code>method descriptor</code>","text":"<p>Expand a ranged string of numbers to a list of unique values.</p> <p>Parameters:</p> Name Type Description Default <code>range_str</code> <code>str</code> <p>A range string, which can for example look like this: \"1,2,3-10,11,15-20\"</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of unique values</p>"},{"location":"reference/utilities/#pyslurm.utils.humanize","title":"<code>pyslurm.utils.humanize(num, decimals=1)</code>  <code>method descriptor</code>","text":"<p>Humanize a number.</p> <p>This will convert the number to a string and add appropriate suffixes like M,G,T,P,...</p> <p>Parameters:</p> Name Type Description Default <code>num</code> <code>int</code> <p>Number to humanize</p> required <code>decimals</code> <code>int</code> <p>Amount of decimals the humanized string should have.</p> <code>1</code> <p>Returns:</p> Type Description <code>str</code> <p>Humanized number with appropriate suffix.</p>"},{"location":"reference/utilities/#pyslurm.utils.dehumanize","title":"<code>pyslurm.utils.dehumanize(humanized_str, target='M', decimals=0)</code>  <code>method descriptor</code>","text":"<p>Dehumanize a previously humanized value.</p> <p>Parameters:</p> Name Type Description Default <code>humanized_str</code> <code>str</code> <p>A humanized str, for example \"5M\" or \"10T\"</p> required <code>target</code> <code>str</code> <p>Target unit. The default is \"M\" (Mebibytes). Allowed values are K,M,G,T,P,E,Z</p> <code>'M'</code> <code>decimals</code> <code>int</code> <p>Amount of decimal places the result should have. Default is 0</p> <code>0</code> <p>Returns:</p> Type Description <code>int</code> <p>Dehumanized value</p>"},{"location":"reference/utilities/#pyslurm.utils.nodelist_from_range_str","title":"<code>pyslurm.utils.nodelist_from_range_str(nodelist)</code>  <code>method descriptor</code>","text":"<p>Convert a bracketed nodelist str with ranges to a list.</p> <p>Parameters:</p> Name Type Description Default <code>nodelist</code> <code>Union[str, list]</code> <p>Comma-seperated str or list with potentially bracketed hostnames and ranges.</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of all nodenames or None on failure</p>"},{"location":"reference/utilities/#pyslurm.utils.nodelist_to_range_str","title":"<code>pyslurm.utils.nodelist_to_range_str(nodelist)</code>  <code>method descriptor</code>","text":"<p>Convert a list of nodes to a bracketed str with ranges.</p> <p>Parameters:</p> Name Type Description Default <code>nodelist</code> <code>Union[str, list]</code> <p>Comma-seperated str or list with unique, unbracketed nodenames.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Bracketed, ranged nodelist or None on failure.</p>"},{"location":"reference/xcollections/","title":"xcollections","text":""},{"location":"reference/xcollections/#pyslurm.xcollections","title":"<code>pyslurm.xcollections</code>","text":"<p>Custom Collection utilities</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap","title":"<code>MultiClusterMap</code>","text":"<p>Mapping of Multi-Cluster Data for a Collection.</p> <p>TL;DR</p> <p>If you have no need to write Multi-Cluster capable code and just work on a single Cluster, Collections inheriting from this Class behave just like a normal <code>dict</code>.</p> <p>This class enables collections to hold data from multiple Clusters if applicable. For quite a few Entities in Slurm it is possible to gather data from multiple Clusters. For example, with <code>sacct</code>, you can easily query Jobs running on different Clusters - provided your Cluster is joined in a Federation or simply part of a multi Cluster Setup.</p> <p>Collections like pyslurm.db.Jobs inherit from this Class to enable holding such data from multiple Clusters. Internally, the data is structured in a <code>dict</code> like this (with pyslurm.db.Jobs as an example):</p> <pre><code>data = {\n    \"LOCAL_CLUSTER\": {\n        1: pyslurm.db.Job(1),\n        2: pyslurm.db.Job(2),\n        ...\n    },\n    \"OTHER_REMOTE_CLUSTER\": {\n        100: pyslurm.db.Job(100),\n        101, pyslurm.db.Job(101)\n        ...\n    },\n    ...\n}\n</code></pre> <p>When a collection inherits from this class, its functionality will basically simulate a standard <code>dict</code> - with a few extensions to enable multi-cluster code. By default, even if your Collections contains Data from multiple Clusters, any operation will be targeted on the local Cluster data, if available.</p> <p>For example, with the data from above:</p> <pre><code>job = data[1]\n</code></pre> <p><code>job</code> would then hold the instance for <code>pyslurm.db.Job(1)</code> from the <code>LOCAL_CLUSTER</code> data.</p> <p>Alternatively, data can also be accessed like this:</p> <pre><code>job = data[\"OTHER_REMOTE_CLUSTER\"][100]\n</code></pre> <p>Here, you are directly specifying which Cluster data you want to access, and you will get the instance for <code>pyslurm.db.Job(100)</code> from the <code>OTHER_REMOTE_CLUSTER</code> data.</p> <p>Similarly, every method (where applicable) from a standard dict is extended with multi-cluster functionality (check out the examples on the methods)</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.add","title":"<code>add(item)</code>  <code>method descriptor</code>","text":"<p>An Item to add to the collection</p> <p>Note that a collection can only hold its specific type. For example, a collection of pyslurm.db.Jobs can only hold pyslurm.db.Job objects. Trying to add anything other than the accepted type will raise a TypeError.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>Any</code> <p>Item to add to the collection.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>When an item with an unexpected type not belonging to the collection was added.</p> <p>Examples:</p> <p>Add a <code>pyslurm.db.Job</code> instance to the <code>pyslurm.db.Jobs</code> collection.</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; jobs = pyslurm.db.Jobs()\n&gt;&gt;&gt; job = pyslurm.db.Job(1)\n&gt;&gt;&gt; jobs.add(job)\n&gt;&gt;&gt; print(jobs)\npyslurm.db.Jobs({1: pyslurm.db.Job(1)})\n</code></pre>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.clear","title":"<code>clear()</code>  <code>method descriptor</code>","text":"<p>Clear the collection</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.clusters","title":"<code>clusters()</code>  <code>method descriptor</code>","text":"<p>Return a View of all the Clusters in this collection</p> <p>Returns:</p> Type Description <code>ClustersView</code> <p>View of Cluster keys</p> <p>Examples:</p> <p>Iterate over all Cluster-Names the Collection contains:</p> <pre><code>&gt;&gt;&gt; for cluster in collection.clusters()\n...     print(cluster)\n</code></pre>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.copy","title":"<code>copy()</code>  <code>method descriptor</code>","text":"<p>Return a Copy of this instance.</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.get","title":"<code>get(key, default=None)</code>  <code>method descriptor</code>","text":"<p>Get the specific value for a Key</p> <p>This behaves like <code>dict</code>'s <code>get</code> method, with the difference that you can additionally pass in a 2-tuple in the form of <code>(cluster, key)</code> as the key, which can be helpful if this collection contains data from multiple Clusters.</p> <p>If just a key without notion of the Cluster is given, access to the local cluster data is implied. If this collection does however not contain data from the local cluster, the first cluster detected according to <code>next(iter(self.keys()))</code> will be used.</p> <p>Examples:</p> <p>Get a Job from the LOCAL_CLUSTER</p> <pre><code>&gt;&gt;&gt; job_id = 1\n&gt;&gt;&gt; job = data.get(job_id)\n</code></pre> <p>Get a Job from another Cluster in the Collection, by providing a 2-tuple with the cluster identifier:</p> <pre><code>&gt;&gt;&gt; job_id = 1\n&gt;&gt;&gt; job = data.get((\"REMOTE_CLUSTER\", job_id))\n</code></pre>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.items","title":"<code>items()</code>  <code>method descriptor</code>","text":"<p>Return a View of all the Values in this collection</p> <p>Returns:</p> Type Description <code>ItemsView</code> <p>View of all Items</p> <p>Examples:</p> <p>Iterate over all Items from all Clusters:</p> <pre><code>&gt;&gt;&gt; for key, value in collection.items()\n...     print(key, value)\n</code></pre> <p>Iterate over all Items from all Clusters with the name of the Cluster additionally provided:</p> <pre><code>&gt;&gt;&gt; for cluster, key, value in collection.items().with_cluster()\n...     print(cluster, key, value)\n</code></pre>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.keys","title":"<code>keys()</code>  <code>method descriptor</code>","text":"<p>Return a View of all the Keys in this collection</p> <p>Returns:</p> Type Description <code>KeysView</code> <p>View of all Keys</p> <p>Examples:</p> <p>Iterate over all Keys from all Clusters:</p> <pre><code>&gt;&gt;&gt; for key in collection.keys()\n...     print(key)\n</code></pre> <p>Iterate over all Keys from all Clusters with the name of the Cluster additionally provided:</p> <pre><code>&gt;&gt;&gt; for cluster, key in collection.keys().with_cluster()\n...     print(cluster, key)\n</code></pre>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.pop","title":"<code>pop(key, default=None)</code>  <code>method descriptor</code>","text":"<p>Remove key from the collection and return the value</p> <p>This behaves like <code>dict</code>'s <code>pop</code> method, with the difference that you can additionally pass in a 2-tuple in the form of <code>(cluster, key)</code> as the key, which can be helpful if this collection contains data from multiple Clusters.</p> <p>If just a key without notion of the Cluster is given, access to the local cluster data is implied. If this collection does however not contain data from the local cluster, the first cluster detected according to <code>next(iter(self.keys()))</code> will be used.</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.popitem","title":"<code>popitem()</code>  <code>method descriptor</code>","text":"<p>Remove and return a <code>(key, value)</code> pair as a 2-tuple</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.to_json","title":"<code>to_json(multi_cluster=False)</code>  <code>method descriptor</code>","text":"<p>Convert the collection to JSON.</p> <p>Returns:</p> Type Description <code>str</code> <p>JSON formatted string from <code>json.dumps()</code></p>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.update","title":"<code>update(data={}, **kwargs)</code>  <code>method descriptor</code>","text":"<p>Update the collection.</p> <p>This functions like <code>dict</code>'s <code>update</code> method.</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.MultiClusterMap.values","title":"<code>values()</code>  <code>method descriptor</code>","text":"<p>Return a View of all the Values in this collection</p> <p>Returns:</p> Type Description <code>ValuesView</code> <p>View of all Values</p> <p>Examples:</p> <p>Iterate over all Values from all Clusters:</p> <pre><code>&gt;&gt;&gt; for value in collection.values()\n...     print(value)\n</code></pre>"},{"location":"reference/xcollections/#pyslurm.xcollections.BaseView","title":"<code>BaseView</code>","text":"<p>Base View for all other Views</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.KeysView","title":"<code>KeysView</code>","text":"<p>               Bases: <code>pyslurm.xcollections.BaseView</code></p> <p>A simple Keys View of a collection</p> <p>When iterating, this yields all the keys found from each Cluster in the collection. Note that unlike the KeysView from a <code>dict</code>, the keys here aren't unique and may appear multiple times.</p> <p>If you indeed have multiple Clusters in a collection and need to tell the keys apart, use the <code>with_cluster()</code> function.</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.KeysView.with_cluster","title":"<code>with_cluster()</code>  <code>method descriptor</code>","text":"<p>Return a Multi-Cluster Keys View.</p> <p>Returns:</p> Type Description <code>MCKeysView</code> <p>Multi-Cluster Keys View.</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.MCKeysView","title":"<code>MCKeysView</code>","text":"<p>               Bases: <code>pyslurm.xcollections.BaseView</code></p> <p>A Multi-Cluster Keys View</p> <p>Unlike KeysView, when iterating over an MCKeysView instance, this will yield a 2-tuple in the form <code>(cluster, key)</code>.</p> <p>Similarly, when checking whether this View contains a Key with the <code>in</code> operator, a 2-tuple must be used in the form described above.</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.ItemsView","title":"<code>ItemsView</code>","text":"<p>               Bases: <code>pyslurm.xcollections.BaseView</code></p> <p>A simple Items View of a collection.</p> <p>Returns a 2-tuple in the form of <code>(key, value)</code> when iterating.</p> <p>Similarly, when checking whether this View contains an Item with the <code>in</code> operator, a 2-tuple must be used.</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.ItemsView.with_cluster","title":"<code>with_cluster()</code>  <code>method descriptor</code>","text":"<p>Return a Multi-Cluster Items View.</p> <p>Returns:</p> Type Description <code>MCItemsView</code> <p>Multi-Cluster Items View.</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.MCItemsView","title":"<code>MCItemsView</code>","text":"<p>               Bases: <code>pyslurm.xcollections.BaseView</code></p> <p>A Multi-Cluster Items View.</p> <p>This differs from ItemsView in that it returns a 3-tuple in the form of <code>(cluster, key, value)</code> when iterating.</p> <p>Similarly, when checking whether this View contains an Item with the <code>in</code> operator, a 3-tuple must be used.</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.ValuesView","title":"<code>ValuesView</code>","text":"<p>               Bases: <code>pyslurm.xcollections.BaseView</code></p> <p>A simple Value View</p> <p>When iterating over an instance of this View, this will yield all values from all clusters.</p>"},{"location":"reference/xcollections/#pyslurm.xcollections.ClustersView","title":"<code>ClustersView</code>","text":"<p>               Bases: <code>pyslurm.xcollections.BaseView</code></p> <p>A simple Cluster-Keys View</p> <p>When iterating over an instance of this View, it will yield all the Cluster names of the collection.</p>"},{"location":"reference/db/","title":"pyslurm.db","text":"<p>The <code>pyslurm.db</code> package contains all functionality to interact with the Slurm Database Daemon (slurmdbd)</p>"},{"location":"reference/db/cluster/","title":"Cluster","text":"<p>Warning</p> <p>This API is currently being completely reworked, and is subject to be removed in the future when a replacement is introduced</p>"},{"location":"reference/db/cluster/#pyslurm.deprecated.slurmdb_clusters","title":"<code>pyslurm.deprecated.slurmdb_clusters</code>","text":"<p>Access Slurmdbd Clusters information.</p>"},{"location":"reference/db/cluster/#pyslurm.deprecated.slurmdb_clusters.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get slurm clusters information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary whose keys are the clusters ids</p>"},{"location":"reference/db/cluster/#pyslurm.deprecated.slurmdb_clusters.set_cluster_condition","title":"<code>set_cluster_condition(start_time, end_time)</code>  <code>method descriptor</code>","text":"<p>Limit the next get() call to clusters that existed after and before a certain time.</p> <p>Parameters:</p> Name Type Description Default <code>start_time</code> <code>int</code> <p>Select clusters that existed after this unix timestamp</p> required <code>end_time</code> <code>int</code> <p>Select clusters that existed before this unix timestamp</p> required"},{"location":"reference/db/connection/","title":"Connection","text":""},{"location":"reference/db/connection/#pyslurm.db.Connection","title":"<code>pyslurm.db.Connection</code>","text":"<p>A connection to the slurmdbd.</p> <p>Attributes:</p> Name Type Description <code>is_open</code> <code>bool</code> <p>Whether the connection is open or closed.</p>"},{"location":"reference/db/connection/#pyslurm.db.Connection.close","title":"<code>close()</code>  <code>method descriptor</code>","text":"<p>Close the current connection.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; connection = pyslurm.db.Connection.open()\n&gt;&gt;&gt; ...\n&gt;&gt;&gt; connection.close()\n&gt;&gt;&gt; print(connection.is_open)\nFalse\n</code></pre>"},{"location":"reference/db/connection/#pyslurm.db.Connection.commit","title":"<code>commit()</code>  <code>method descriptor</code>","text":"<p>Commit recent changes.</p>"},{"location":"reference/db/connection/#pyslurm.db.Connection.open","title":"<code>open()</code>  <code>staticmethod</code>","text":"<p>Open a new connection to the slurmdbd</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When opening the connection fails</p> <p>Returns:</p> Type Description <code>Connection</code> <p>Connection to slurmdbd</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; connection = pyslurm.db.Connection.open()\n&gt;&gt;&gt; print(connection.is_open)\nTrue\n</code></pre>"},{"location":"reference/db/connection/#pyslurm.db.Connection.rollback","title":"<code>rollback()</code>  <code>method descriptor</code>","text":"<p>Rollback recent changes.</p>"},{"location":"reference/db/event/","title":"Event","text":"<p>Warning</p> <p>This API is currently being completely reworked, and is subject to be removed in the future when a replacement is introduced</p>"},{"location":"reference/db/event/#pyslurm.deprecated.slurmdb_events","title":"<code>pyslurm.deprecated.slurmdb_events</code>","text":"<p>Access Slurmdbd events information.</p>"},{"location":"reference/db/event/#pyslurm.deprecated.slurmdb_events.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get slurm events information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary whose keys are the events ids</p>"},{"location":"reference/db/event/#pyslurm.deprecated.slurmdb_events.set_event_condition","title":"<code>set_event_condition(start_time, end_time)</code>  <code>method descriptor</code>","text":"<p>Limit the next get() call to conditions that existed after and before a certain time.</p> <p>Parameters:</p> Name Type Description Default <code>start_time</code> <code>int</code> <p>Select conditions that existed after this unix timestamp</p> required <code>end_time</code> <code>int</code> <p>Select conditions that existed before this unix timestamp</p> required"},{"location":"reference/db/job/","title":"Job","text":"<p>Note</p> <p>This supersedes the pyslurm.slurmdb_job class, which will be removed in a future release</p>"},{"location":"reference/db/job/#pyslurm.db.Job","title":"<code>pyslurm.db.Job</code>","text":"<p>A Slurm Database Job.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>int</code> <p>An Integer representing a Job-ID.</p> <code>0</code> <code>cluster</code> <code>str</code> <p>Name of the Cluster for this Job. Default is the name of the local Cluster.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>admin_comment</code> <code>str</code> <p>Admin comment for the Job.</p> <code>comment</code> <code>str</code> <p>Comment for the Job</p> <code>wckey</code> <code>str</code> <p>Name of the WCKey for this Job</p> <code>derived_exit_code</code> <code>int</code> <p>Highest exit code of all the Job steps</p> <code>extra</code> <code>str</code> <p>Arbitrary string that can be stored with a Job.</p> <p>Attributes:</p> Name Type Description <code>steps</code> <code>JobSteps</code> <p>Steps this Job has</p> <code>stats</code> <code>JobStatistics</code> <p>Utilization statistics of this Job</p> <code>account</code> <code>str</code> <p>Account of the Job.</p> <code>admin_comment</code> <code>str</code> <p>Admin comment for the Job.</p> <code>num_nodes</code> <code>int</code> <p>Amount of nodes this Job has allocated (if it is running) or requested (if it is still pending).</p> <code>array_id</code> <code>int</code> <p>The master Array-Job ID.</p> <code>array_tasks_parallel</code> <code>int</code> <p>Max number of array tasks allowed to run simultaneously.</p> <code>array_task_id</code> <code>int</code> <p>Array Task ID of this Job if it is an Array-Job.</p> <code>array_tasks_waiting</code> <code>str</code> <p>Array Tasks that are still waiting.</p> <code>association_id</code> <code>int</code> <p>ID of the Association this job runs in.</p> <code>block_id</code> <code>str</code> <p>Name of the block used (for BlueGene Systems)</p> <code>cluster</code> <code>str</code> <p>Cluster this Job belongs to</p> <code>constraints</code> <code>str</code> <p>Constraints of the Job</p> <code>container</code> <code>str</code> <p>Path to OCI Container bundle</p> <code>db_index</code> <code>int</code> <p>Unique database index of the Job in the job table</p> <code>derived_exit_code</code> <code>int</code> <p>Highest exit code of all the Job steps</p> <code>derived_exit_code_signal</code> <code>int</code> <p>Signal of the derived exit code</p> <code>comment</code> <code>str</code> <p>Comment for the Job</p> <code>elapsed_time</code> <code>int</code> <p>Amount of seconds elapsed for the Job</p> <code>eligible_time</code> <code>int</code> <p>When the Job became eligible to run, as a unix timestamp</p> <code>end_time</code> <code>int</code> <p>When the Job ended, as a unix timestamp</p> <code>extra</code> <code>str</code> <p>Arbitrary string that can be stored with a Job.</p> <code>exit_code</code> <code>int</code> <p>Exit code of the job script or salloc.</p> <code>exit_code_signal</code> <code>int</code> <p>Signal of the exit code for this Job.</p> <code>failed_node</code> <code>str</code> <p>Name of the failed node that caused the job to get killed.</p> <code>group_id</code> <code>int</code> <p>ID of the group for this Job</p> <code>group_name</code> <code>str</code> <p>Name of the group for this Job</p> <code>id</code> <code>int</code> <p>ID of the Job</p> <code>name</code> <code>str</code> <p>Name of the Job</p> <code>mcs_label</code> <code>str</code> <p>MCS Label of the Job</p> <code>nodelist</code> <code>str</code> <p>Nodes this Job is using</p> <code>partition</code> <code>str</code> <p>Name of the Partition for this Job</p> <code>priority</code> <code>int</code> <p>Priority for the Job</p> <code>qos</code> <code>str</code> <p>Name of the Quality of Service for the Job</p> <code>cpus</code> <code>int</code> <p>Amount of CPUs the Job has/had allocated, or, if the Job is still pending, this will reflect the amount requested.</p> <code>memory</code> <code>int</code> <p>Amount of memory the Job requested in total, in Mebibytes</p> <code>reservation</code> <code>str</code> <p>Name of the Reservation for this Job</p> <code>script</code> <code>str</code> <p>The batch script for this Job. Note: Only available if the \"with_script\" condition was given</p> <code>start_time</code> <code>int</code> <p>Time when the Job started, as a unix timestamp</p> <code>state</code> <code>str</code> <p>State of the Job</p> <code>state_reason</code> <code>str</code> <p>Last reason a Job was blocked from running</p> <code>cancelled_by</code> <code>str</code> <p>Name of the User who cancelled this Job</p> <code>submit_time</code> <code>int</code> <p>Time the Job was submitted, as a unix timestamp</p> <code>submit_command</code> <code>str</code> <p>Full command issued to submit the Job</p> <code>suspended_time</code> <code>int</code> <p>Amount of seconds the Job was suspended</p> <code>system_comment</code> <code>str</code> <p>Arbitrary System comment for the Job</p> <code>time_limit</code> <code>int</code> <p>Time limit of the Job in minutes</p> <code>user_id</code> <code>int</code> <p>UID of the User this Job belongs to</p> <code>user_name</code> <code>str</code> <p>Name of the User this Job belongs to</p> <code>wckey</code> <code>str</code> <p>Name of the WCKey for this Job</p> <code>working_directory</code> <code>str</code> <p>Working directory of the Job</p>"},{"location":"reference/db/job/#pyslurm.db.Job.load","title":"<code>load(job_id, cluster=None, with_script=False, with_env=False)</code>  <code>staticmethod</code>","text":"<p>Load the information for a specific Job from the Database.</p> <p>Parameters:</p> Name Type Description Default <code>job_id</code> <code>int</code> <p>ID of the Job to be loaded.</p> required <code>cluster</code> <code>str</code> <p>Name of the Cluster to search in. Default is the local Cluster.</p> <code>None</code> <code>with_script</code> <code>bool</code> <p>Whether the Job-Script should also be loaded. Mutually exclusive with <code>with_env</code>.</p> <code>False</code> <code>with_env</code> <code>bool</code> <p>Whether the Job Environment should also be loaded. Mutually exclusive with <code>with_script</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>Job</code> <p>Returns a new Database Job instance</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>If requesting the information for the database Job was not successful.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; db_job = pyslurm.db.Job.load(10000)\n</code></pre> <p>In the above example, attributes like <code>script</code> and <code>environment</code> are not populated. You must explicitly request one of them to be loaded:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; db_job = pyslurm.db.Job.load(10000, with_script=True)\n&gt;&gt;&gt; print(db_job.script)\n</code></pre>"},{"location":"reference/db/job/#pyslurm.db.Job.modify","title":"<code>modify(changes, db_connection=None)</code>  <code>method descriptor</code>","text":"<p>Modify a Slurm database Job.</p> <p>Parameters:</p> Name Type Description Default <code>changes</code> <code>Job</code> <p>Another pyslurm.db.Job object that contains all the changes to apply. Check the <code>Other Parameters</code> of the pyslurm.db.Job class to see which properties can be modified.</p> required <code>db_connection</code> <code>Connection</code> <p>A slurmdbd connection. See pyslurm.db.Jobs.modify for more info on this parameter.</p> <code>None</code> <p>Raises:</p> Type Description <code>RPCError</code> <p>When modifying the Job failed.</p>"},{"location":"reference/db/job/#pyslurm.db.Job.to_dict","title":"<code>to_dict()</code>  <code>method descriptor</code>","text":"<p>Convert Database Job information to a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Database Job information as dict</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; myjob = pyslurm.db.Job.load(10000)\n&gt;&gt;&gt; myjob_dict = myjob.to_dict()\n</code></pre>"},{"location":"reference/db/job/#pyslurm.db.Jobs","title":"<code>pyslurm.db.Jobs</code>","text":"<p>               Bases: <code>pyslurm.xcollections.MultiClusterMap</code></p> <p>A <code>Multi Cluster</code> collection of pyslurm.db.Job objects.</p> <p>Parameters:</p> Name Type Description Default <code>jobs</code> <code>Union[list[int], dict[int, Job], str]</code> <p>Jobs to initialize this collection with.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>stats</code> <code>JobStatistics</code> <p>Utilization statistics of this Job Collection</p> <code>cpus</code> <code>int</code> <p>Total amount of cpus requested.</p> <code>nodes</code> <code>int</code> <p>Total amount of nodes requested.</p> <code>memory</code> <code>int</code> <p>Total amount of requested memory in Mebibytes.</p>"},{"location":"reference/db/job/#pyslurm.db.Jobs.calc_stats","title":"<code>calc_stats()</code>  <code>method descriptor</code>","text":"<p>(Re)Calculate Statistics for the Job Collection.</p>"},{"location":"reference/db/job/#pyslurm.db.Jobs.load","title":"<code>load(db_filter=None, db_connection=None)</code>  <code>staticmethod</code>","text":"<p>Load Jobs from the Slurm Database</p> <p>Implements the slurmdb_jobs_get RPC.</p> <p>Parameters:</p> Name Type Description Default <code>db_filter</code> <code>JobFilter</code> <p>A search filter that the slurmdbd will apply when retrieving Jobs from the database.</p> <code>None</code> <code>db_connection</code> <code>Connection</code> <p>An open database connection. By default if none is specified, one will be opened automatically.</p> <code>None</code> <p>Returns:</p> Type Description <code>Jobs</code> <p>A Collection of database Jobs.</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When getting the Jobs from the Database was not successful</p> <p>Examples:</p> <p>Without a Filter the default behaviour applies, which is simply retrieving all Jobs from the same day:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; db_jobs = pyslurm.db.Jobs.load()\n&gt;&gt;&gt; print(db_jobs)\npyslurm.db.Jobs({1: pyslurm.db.Job(1), 2: pyslurm.db.Job(2)})\n&gt;&gt;&gt; print(db_jobs[1])\npyslurm.db.Job(1)\n</code></pre> <p>Now with a Job Filter, so only Jobs that have specific Accounts are returned:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt; accounts = [\"acc1\", \"acc2\"]\n&gt;&gt;&gt; db_filter = pyslurm.db.JobFilter(accounts=accounts)\n&gt;&gt;&gt; db_jobs = pyslurm.db.Jobs.load(db_filter)\n</code></pre>"},{"location":"reference/db/job/#pyslurm.db.Jobs.modify","title":"<code>modify(db_filter, changes, db_connection=None)</code>  <code>staticmethod</code>","text":"<p>Modify Slurm database Jobs.</p> <p>Implements the slurm_job_modify RPC.</p> <p>Parameters:</p> Name Type Description Default <code>db_filter</code> <code>Union[JobFilter, Jobs]</code> <p>A filter to decide which Jobs should be modified.</p> required <code>changes</code> <code>Job</code> <p>Another pyslurm.db.Job object that contains all the changes to apply. Check the <code>Other Parameters</code> of the pyslurm.db.Job class to see which properties can be modified.</p> required <code>db_connection</code> <code>Connection</code> <p>A Connection to the slurmdbd. By default, if no connection is supplied, one will automatically be created internally. This means that when the changes were considered successful by the slurmdbd, those modifications will be automatically committed.</p> <p>If you however decide to provide your own Connection instance (which must be already opened before), and the changes were successful, they will basically be in a kind of \"staging area\". By the time this function returns, the changes are not actually made. You are then responsible to decide whether the changes should be committed or rolled back by using the respective methods on the connection object. This way, you have a chance to see which Jobs were modified before you commit the changes.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[int]</code> <p>A list of Jobs that were modified</p> <p>Raises:</p> Type Description <code>RPCError</code> <p>When a failure modifying the Jobs occurred.</p> <p>Examples:</p> <p>In its simplest form, you can do something like this:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt;\n&gt;&gt;&gt; db_filter = pyslurm.db.JobFilter(ids=[9999])\n&gt;&gt;&gt; changes = pyslurm.db.Job(comment=\"A comment for the job\")\n&gt;&gt;&gt; modified_jobs = pyslurm.db.Jobs.modify(db_filter, changes)\n&gt;&gt;&gt; print(modified_jobs)\n[9999]\n</code></pre> <p>In the above example, the changes will be automatically committed if successful. You can however also control this manually by providing your own connection object:</p> <pre><code>&gt;&gt;&gt; import pyslurm\n&gt;&gt;&gt;\n&gt;&gt;&gt; db_conn = pyslurm.db.Connection.open()\n&gt;&gt;&gt; db_filter = pyslurm.db.JobFilter(ids=[9999])\n&gt;&gt;&gt; changes = pyslurm.db.Job(comment=\"A comment for the job\")\n&gt;&gt;&gt; modified_jobs = pyslurm.db.Jobs.modify(\n...             db_filter, changes, db_conn)\n</code></pre> <p>Now you can first examine which Jobs have been modified:</p> <pre><code>&gt;&gt;&gt; print(modified_jobs)\n[9999]\n</code></pre> <p>And then you can actually commit the changes:</p> <pre><code>&gt;&gt;&gt; db_conn.commit()\n</code></pre> <p>You can also explicitly rollback these changes instead of committing, so they will not become active:</p> <pre><code>&gt;&gt;&gt; db_conn.rollback()\n</code></pre>"},{"location":"reference/db/jobfilter/","title":"JobFilter","text":""},{"location":"reference/db/jobfilter/#pyslurm.db.JobFilter","title":"<code>pyslurm.db.JobFilter</code>","text":"<p>Query-Conditions for Jobs in the Slurm Database.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Any valid attribute of the object.</p> required <p>Attributes:</p> Name Type Description <code>ids</code> <code>list[int]</code> <p>A list of Job ids to search for.</p> <code>start_time</code> <code>Union[str, int, datetime]</code> <p>Search for Jobs which started after this time.</p> <code>end_time</code> <code>Union[str, int, datetime]</code> <p>Search for Jobs which ended before this time.</p> <code>accounts</code> <code>list[str]</code> <p>Search for Jobs with these account names.</p> <code>association_ids</code> <code>list[int]</code> <p>Search for Jobs with these association ids.</p> <code>clusters</code> <code>list[str]</code> <p>Search for Jobs running in these clusters.</p> <code>constraints</code> <code>list[str]</code> <p>Search for Jobs with these constraints.</p> <code>cpus</code> <code>int</code> <p>Search for Jobs with exactly this many CPUs. Note: If you also specify <code>max_cpus</code>, then this value will act as the minimum.</p> <code>max_cpus</code> <code>int</code> <p>Search for Jobs with no more than this amount of CPUs. Note: This value has no effect without also setting <code>cpus</code>.</p> <code>nodes</code> <code>int</code> <p>Search for Jobs with exactly this many nodes. Note: If you also specify <code>max_nodes</code>, then this value will act as the minimum.</p> <code>max_nodes</code> <code>int</code> <p>Search for Jobs with no more than this amount of nodes. Note: This value has no effect without also setting <code>nodes</code>.</p> <code>qos</code> <code>list[str]</code> <p>Search for Jobs with these Qualities of Service.</p> <code>names</code> <code>list[str]</code> <p>Search for Jobs with these job names.</p> <code>partitions</code> <code>list[str]</code> <p>Search for Jobs with these partition names.</p> <code>groups</code> <code>list[str]</code> <p>Search for Jobs with these group names. Alternatively, you can also specify the GIDs directly.</p> <code>timelimit</code> <code>Union[str, int]</code> <p>Search for Jobs with exactly this timelimit. Note: If you also specify <code>max_timelimit</code>, then this value will act as the minimum.</p> <code>max_timelimit</code> <code>Union[str, int]</code> <p>Search for Jobs which run no longer than this timelimit Note: This value has no effect without also setting <code>timelimit</code></p> <code>users</code> <code>list[str]</code> <p>Search for Jobs with these user names. Alternatively, you can also specify the UIDs directly.</p> <code>wckeys</code> <code>list[str]</code> <p>Search for Jobs with these WCKeys</p> <code>nodelist</code> <code>list[str]</code> <p>Search for Jobs that ran on any of these Nodes</p> <code>with_script</code> <code>bool</code> <p>Instruct the slurmdbd to also send the job script(s) Note: This requires specifying explictiy job ids, and is mutually exclusive with <code>with_env</code></p> <code>with_env</code> <code>bool</code> <p>Instruct the slurmdbd to also send the job environment(s) Note: This requires specifying explictiy job ids, and is mutually exclusive with <code>with_script</code></p> <code>truncate_time</code> <code>bool</code> <p>Truncate start and end time. For example, when a Job has actually started before the requested <code>start_time</code>, the time will be truncated to <code>start_time</code>. Same logic applies for <code>end_time</code>. This is like the <code>-T</code> / <code>--truncate</code> option from <code>sacct</code>.</p>"},{"location":"reference/db/jobstats/","title":"JobStatistics","text":""},{"location":"reference/db/jobstats/#pyslurm.db.JobStatistics","title":"<code>pyslurm.db.JobStatistics</code>","text":"<p>Statistics for a Slurm Job or Job Collection.</p> <p>Attributes:</p> Name Type Description <code>total_cpu_time</code> <code>int</code> <p>Sum of user_cpu_time and system_cpu_time, in seconds</p> <code>user_cpu_time</code> <code>int</code> <p>Total amount of time spent in user space, in seconds</p> <code>system_cpu_time</code> <code>int</code> <p>Total amount of time spent in kernel space, in seconds</p> <code>consumed_energy</code> <code>int</code> <p>Total amount of energy consumed, in joules</p> <code>elapsed_cpu_time</code> <code>int</code> <p>Total amount of time used(Elapsed time * cpu count) in seconds. This is not the real CPU-Efficiency, but rather the total amount of cpu-time the CPUs were occupied for.</p> <code>disk_read</code> <code>int</code> <p>Total amount of bytes read.</p> <code>disk_write</code> <code>int</code> <p>Total amount of bytes written.</p> <code>page_faults</code> <code>int</code> <p>Total amount of page faults.</p> <code>resident_memory</code> <code>int</code> <p>Total Resident Set Size (RSS) used in bytes.</p> <code>virtual_memory</code> <code>int</code> <p>Total Virtual Memory Size (VSZ) used in bytes.</p>"},{"location":"reference/db/jobstats/#pyslurm.db.JobStepStatistics","title":"<code>pyslurm.db.JobStepStatistics</code>","text":"<p>Statistics for a Slurm JobStep.</p> <p>Note</p> <p>For more information also see the sacct manpage.</p> <p>Attributes:</p> Name Type Description <code>consumed_energy</code> <code>int</code> <p>Total amount of energy consumed, in joules</p> <code>elapsed_cpu_time</code> <code>int</code> <p>Total amount of time used(Elapsed time * cpu count) in seconds. This is not the real CPU-Efficiency, but rather the total amount of cpu-time the CPUs were occupied for</p> <code>avg_cpu_time</code> <code>int</code> <p>Average CPU-Time (System + User) in seconds of all tasks</p> <code>avg_cpu_frequency</code> <code>int</code> <p>Average weighted CPU-Frequency of all tasks, in Kilohertz</p> <code>avg_disk_read</code> <code>int</code> <p>Average number of bytes read by all tasks</p> <code>avg_disk_write</code> <code>int</code> <p>Average number of bytes written by all tasks</p> <code>avg_page_faults</code> <code>int</code> <p>Average number of page faults by all tasks</p> <code>avg_resident_memory</code> <code>int</code> <p>Average Resident Set Size (RSS) in bytes of all tasks</p> <code>avg_virtual_memory</code> <code>int</code> <p>Average Virtual Memory Size (VSZ) in bytes of all tasks</p> <code>max_disk_read</code> <code>int</code> <p>Highest peak number of bytes read by all tasks</p> <code>max_disk_read_node</code> <code>int</code> <p>Name of the Node where max_disk_read occurred</p> <code>max_disk_read_task</code> <code>int</code> <p>ID of the Task where max_disk_read occurred</p> <code>max_disk_write</code> <code>int</code> <p>Lowest peak number of bytes written by all tasks</p> <code>max_disk_write_node</code> <code>int</code> <p>Name of the Node where max_disk_write occurred</p> <code>max_disk_write_task</code> <code>int</code> <p>ID of the Task where max_disk_write occurred</p> <code>max_page_faults</code> <code>int</code> <p>Highest peak number of page faults by all tasks</p> <code>max_page_faults_node</code> <code>int</code> <p>Name of the Node where max_page_faults occurred</p> <code>max_page_faults_task</code> <code>int</code> <p>ID of the Task where max_page_faults occurred</p> <code>max_resident_memory</code> <code>int</code> <p>Highest peak Resident Set Size (RSS) in bytes by all tasks</p> <code>max_resident_memory_node</code> <code>int</code> <p>Name of the Node where max_resident_memory occurred</p> <code>max_resident_memory_task</code> <code>int</code> <p>ID of the Task where max_resident_memory occurred</p> <code>max_virtual_memory</code> <code>int</code> <p>Highest peak Virtual Memory Size (VSZ) in bytes by all tasks</p> <code>max_virtual_memory_node</code> <code>int</code> <p>Name of the Node where max_virtual_memory occurred</p> <code>max_virtual_memory_task</code> <code>int</code> <p>ID of the Task where max_virtual_memory occurred</p> <code>min_cpu_time</code> <code>int</code> <p>Lowest peak CPU-Time (System + User) in seconds of all tasks</p> <code>min_cpu_time_node</code> <code>int</code> <p>Name of the Node where min_cpu_time occurred</p> <code>min_cpu_time_task</code> <code>int</code> <p>ID of the Task where min_cpu_time occurred</p> <code>total_cpu_time</code> <code>int</code> <p>Sum of user_cpu_time and system_cpu_time, in seconds</p> <code>user_cpu_time</code> <code>int</code> <p>Amount of Time spent in user space, in seconds</p> <code>system_cpu_time</code> <code>int</code> <p>Amount of Time spent in kernel space, in seconds</p>"},{"location":"reference/db/jobstep/","title":"JobStep","text":""},{"location":"reference/db/jobstep/#pyslurm.db.JobStep","title":"<code>pyslurm.db.JobStep</code>","text":"<p>A Slurm Database JobStep.</p> <p>Attributes:</p> Name Type Description <code>stats</code> <code>JobStepStatistics</code> <p>Utilization statistics for this Step</p> <code>num_nodes</code> <code>int</code> <p>Amount of nodes this Step has allocated</p> <code>cpus</code> <code>int</code> <p>Amount of CPUs the Step has/had allocated</p> <code>memory</code> <code>int</code> <p>Amount of memory the Step requested</p> <code>container</code> <code>str</code> <p>Path to OCI Container bundle</p> <code>elapsed_time</code> <code>int</code> <p>Amount of seconds elapsed for the Step</p> <code>end_time</code> <code>int</code> <p>When the Step ended, as a unix timestamp</p> <code>eligible_time</code> <code>int</code> <p>When the Step became eligible to run, as a unix timestamp</p> <code>start_time</code> <code>int</code> <p>Time when the Step started, as a unix timestamp</p> <code>exit_code</code> <code>int</code> <p>Exit code of the step</p> <code>ntasks</code> <code>int</code> <p>Number of tasks the Step uses</p> <code>cpu_frequency_min</code> <code>str</code> <p>Minimum CPU-Frequency requested for the Step</p> <code>cpu_frequency_max</code> <code>str</code> <p>Maximum CPU-Frequency requested for the Step</p> <code>cpu_frequency_governor</code> <code>str</code> <p>CPU-Frequency Governor requested for the Step</p> <code>nodelist</code> <code>str</code> <p>Nodes this Step is using</p> <code>id</code> <code>Union[str, int]</code> <p>ID of the Step</p> <code>job_id</code> <code>int</code> <p>ID of the Job this Step is a part of</p> <code>state</code> <code>str</code> <p>State of the Step</p> <code>cancelled_by</code> <code>str</code> <p>Name of the User who cancelled this Step</p> <code>submit_command</code> <code>str</code> <p>Full command issued to start the Step</p> <code>suspended_time</code> <code>int</code> <p>Amount of seconds the Step was suspended</p>"},{"location":"reference/db/jobstep/#pyslurm.db.JobStep.to_dict","title":"<code>to_dict()</code>  <code>method descriptor</code>","text":"<p>Convert Database JobStep information to a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Database JobStep information as dict</p>"},{"location":"reference/db/jobstep/#pyslurm.db.JobSteps","title":"<code>pyslurm.db.JobSteps</code>","text":"<p>               Bases: <code>builtins.dict</code></p> <p>A dict of pyslurm.db.JobStep objects</p>"},{"location":"reference/db/reservation/","title":"Reservation","text":"<p>Warning</p> <p>This API is currently being completely reworked, and is subject to be removed in the future when a replacement is introduced</p>"},{"location":"reference/db/reservation/#pyslurm.deprecated.slurmdb_reservations","title":"<code>pyslurm.deprecated.slurmdb_reservations</code>","text":"<p>Access Slurmdbd reservations information.</p>"},{"location":"reference/db/reservation/#pyslurm.deprecated.slurmdb_reservations.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get slurm reservations information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary whose keys are the reservations ids</p>"},{"location":"reference/db/reservation/#pyslurm.deprecated.slurmdb_reservations.set_reservation_condition","title":"<code>set_reservation_condition(start_time, end_time)</code>  <code>method descriptor</code>","text":"<p>Limit the next get() call to reservations that start after and before a certain time.</p> <p>Parameters:</p> Name Type Description Default <code>start_time</code> <code>int</code> <p>Select reservations that start after this unix timestamp</p> required <code>end_time</code> <code>int</code> <p>Select reservations that end before this unix timestamp</p> required"},{"location":"reference/old/job/","title":"Job","text":"<p>Warning</p> <p>This class is superseded by pyslurm.Job and will be removed in a future release.</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job","title":"<code>pyslurm.deprecated.job</code>","text":"<p>Slurm Job Information.</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job.find","title":"<code>find(name='', val='')</code>  <code>method descriptor</code>","text":"<p>Search for a property and associated value in the retrieved job data.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>key string to search</p> <code>''</code> <code>val</code> <code>str</code> <p>value string to match</p> <code>''</code> <p>Returns:</p> Type Description <code>list</code> <p>List of IDs that match</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job.find_id","title":"<code>find_id(jobid)</code>  <code>method descriptor</code>","text":"<p>Retrieve job ID data.</p> <p>This method accepts both string and integer formats of the jobid. This works for single jobs and job arrays. It uses the internal helper _load_single_job to do slurm_load_job. If the job corresponding to the jobid does not exist, a ValueError will be raised.</p> <p>Parameters:</p> Name Type Description Default <code>jobid</code> <code>str</code> <p>Job id key string to search</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of dictionary of values for given job id</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job.find_user","title":"<code>find_user(user)</code>  <code>method descriptor</code>","text":"<p>Retrieve a user's job data.</p> <p>This method calls slurm_load_job_user to get all job_table records associated with a specific user.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>User string to search</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of values for all user's jobs</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get all slurm jobs information.</p> <p>This method calls slurm_load_jobs to get job_table records for all jobs</p> <p>Returns:</p> Type Description <code>dict</code> <p>Data where key is the job name, each entry contains a dictionary of job attributes</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job.ids","title":"<code>ids()</code>  <code>method descriptor</code>","text":"<p>Return the job IDs from retrieved data.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of job IDs</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job.lastBackfill","title":"<code>lastBackfill()</code>  <code>method descriptor</code>","text":"<p>Get the time (epoch seconds) of last backfilling run.</p> <p>Returns:</p> Type Description <code>int</code> <p>Epoch seconds</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job.lastUpdate","title":"<code>lastUpdate()</code>  <code>method descriptor</code>","text":"<p>Get the time (epoch seconds) the job data was updated.</p> <p>Returns:</p> Type Description <code>int</code> <p>Epoch seconds</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job.slurm_job_batch_script","title":"<code>slurm_job_batch_script(jobid)</code>  <code>method descriptor</code>","text":"<p>Return the contents of the batch-script for a Job.</p> <p>The string returned also includes all the \"\\n\" characters (new-line).</p> <p>Parameters:</p> Name Type Description Default <code>jobid</code> <code>Union[str, int]</code> <p>ID of the Job for which the script should be retrieved.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The content of the batch script.</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job.submit_batch_job","title":"<code>submit_batch_job(job_opts)</code>  <code>method descriptor</code>","text":"<p>Submit batch job.</p> <p>Make sure options match sbatch command line opts and not struct member names.</p> <p>Parameters:</p> Name Type Description Default <code>job_opts</code> <code>dict</code> <p>Job information.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The job id of the submitted job.</p>"},{"location":"reference/old/job/#pyslurm.deprecated.job.wait_finished","title":"<code>wait_finished(jobid)</code>  <code>method descriptor</code>","text":"<p>Block until the job given by the jobid finishes.</p> <p>This works for single jobs, as well as job arrays.</p> <p>Parameters:</p> Name Type Description Default <code>jobid</code> <code>int</code> <p>The job id of the slurm job. To reference a job with job array set, use the first/\"master\" jobid (the same as given by squeue)</p> required <p>Returns:</p> Type Description <code>int</code> <p>The exit code of the slurm job.</p>"},{"location":"reference/old/jobstep/","title":"JobStep","text":"<p>Warning</p> <p>This class is superseded by pyslurm.JobStep and will be removed in a future release.</p>"},{"location":"reference/old/jobstep/#pyslurm.deprecated.jobstep","title":"<code>pyslurm.deprecated.jobstep</code>","text":"<p>Access/Modify Slurm Jobstep Information.</p>"},{"location":"reference/old/jobstep/#pyslurm.deprecated.jobstep.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get slurm jobstep information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Data whose key is the jobstep ID.</p>"},{"location":"reference/old/jobstep/#pyslurm.deprecated.jobstep.lastUpdate","title":"<code>lastUpdate()</code>  <code>method descriptor</code>","text":"<p>Get the time (epoch seconds) the jobstep data was updated.</p> <p>Returns:</p> Type Description <code>int</code> <p>Epoch seconds</p>"},{"location":"reference/old/jobstep/#pyslurm.deprecated.jobstep.layout","title":"<code>layout(JobID=0, StepID=0)</code>  <code>method descriptor</code>","text":"<p>Get the slurm job step layout from a given job and step id.</p> <p>Parameters:</p> Name Type Description Default <code>JobID</code> <code>int</code> <p>The job id.</p> <code>0</code> <code>StepID</code> <code>int</code> <p>The id of the job step.</p> <code>0</code> <p>Returns:</p> Type Description <code>list</code> <p>List of job step layout.</p>"},{"location":"reference/old/node/","title":"Node","text":"<p>Warning</p> <p>This class is superseded by pyslurm.Node and will be removed in a future release.</p>"},{"location":"reference/old/node/#pyslurm.deprecated.node","title":"<code>pyslurm.deprecated.node</code>","text":"<p>Access/Modify/Update Slurm Node Information.</p>"},{"location":"reference/old/node/#pyslurm.deprecated.node.find_id","title":"<code>find_id(nodeID)</code>  <code>method descriptor</code>","text":"<p>Get node information for a given node.</p> <p>Parameters:</p> Name Type Description Default <code>nodeID</code> <code>str</code> <p>Node key string to search</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of values for given node</p>"},{"location":"reference/old/node/#pyslurm.deprecated.node.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get all slurm node information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of dictionaries whose key is the node name.</p>"},{"location":"reference/old/node/#pyslurm.deprecated.node.get_node","title":"<code>get_node(nodeID)</code>  <code>method descriptor</code>","text":"<p>Get single slurm node information.</p> <p>Parameters:</p> Name Type Description Default <code>nodeID</code> <code>str</code> <p>Node key string to search. Default NULL.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of node info data.</p>"},{"location":"reference/old/node/#pyslurm.deprecated.node.ids","title":"<code>ids()</code>  <code>method descriptor</code>","text":"<p>Return the node IDs from retrieved data.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of node IDs</p>"},{"location":"reference/old/node/#pyslurm.deprecated.node.lastUpdate","title":"<code>lastUpdate()</code>  <code>method descriptor</code>","text":"<p>Return last time (epoch seconds) the node data was updated.</p> <p>Returns:</p> Type Description <code>int</code> <p>Epoch seconds</p>"},{"location":"reference/old/node/#pyslurm.deprecated.node.print_node_info_msg","title":"<code>print_node_info_msg(oneLiner=False)</code>  <code>method descriptor</code>","text":"<p>Output information about all slurm nodes.</p> <p>Parameters:</p> Name Type Description Default <code>oneLiner</code> <code>int</code> <p>Print on one line</p> <code>False</code>"},{"location":"reference/old/node/#pyslurm.deprecated.node.update","title":"<code>update(node_dict)</code>  <code>method descriptor</code>","text":"<p>Update slurm node information.</p> <p>Parameters:</p> Name Type Description Default <code>node_dict</code> <code>dict</code> <p>A populated node dictionary, an empty one is created by create_node_dict</p> required <p>Returns:</p> Type Description <code>int</code> <p>0 for success or -1 for error, and the slurm error code is set appropriately.</p>"},{"location":"reference/old/partition/","title":"Partition","text":"<p>Warning</p> <p>This class is superseded by pyslurm.Partition and will be removed in a future release.</p>"},{"location":"reference/old/partition/#pyslurm.deprecated.partition","title":"<code>pyslurm.deprecated.partition</code>","text":"<p>Slurm Partition Information.</p>"},{"location":"reference/old/partition/#pyslurm.deprecated.partition.create","title":"<code>create(Partition_dict)</code>  <code>method descriptor</code>","text":"<p>Create a slurm partition.</p> <p>Parameters:</p> Name Type Description Default <code>Partition_dict</code> <code>dict</code> <p>A populated partition dictionary, an empty one can be created by create_partition_dict</p> required <p>Returns:</p> Type Description <code>int</code> <p>0 for success or -1 for error, and the slurm error code is set appropriately.</p>"},{"location":"reference/old/partition/#pyslurm.deprecated.partition.delete","title":"<code>delete(PartID)</code>  <code>method descriptor</code>","text":"<p>Delete a give slurm partition.</p> <p>Parameters:</p> Name Type Description Default <code>PartID</code> <code>str</code> <p>Name of slurm partition</p> required <p>Returns:</p> Type Description <code>int</code> <p>0 for success else set the slurm error code as appropriately.</p>"},{"location":"reference/old/partition/#pyslurm.deprecated.partition.find","title":"<code>find(name='', val='')</code>  <code>method descriptor</code>","text":"<p>Search for a property and associated value in the retrieved partition data.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>key string to search</p> <code>''</code> <code>val</code> <code>str</code> <p>value string to match</p> <code>''</code> <p>Returns:</p> Type Description <code>list</code> <p>List of IDs that match</p>"},{"location":"reference/old/partition/#pyslurm.deprecated.partition.find_id","title":"<code>find_id(partID)</code>  <code>method descriptor</code>","text":"<p>Get partition information for a given partition.</p> <p>Parameters:</p> Name Type Description Default <code>partID</code> <code>str</code> <p>Partition key string to search</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of values for given partition</p>"},{"location":"reference/old/partition/#pyslurm.deprecated.partition.get","title":"<code>get()</code>  <code>method descriptor</code>","text":"<p>Get all slurm partition information</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of dictionaries whose key is the partition name.</p>"},{"location":"reference/old/partition/#pyslurm.deprecated.partition.ids","title":"<code>ids()</code>  <code>method descriptor</code>","text":"<p>Return the partition IDs from retrieved data.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of partition IDs</p>"},{"location":"reference/old/partition/#pyslurm.deprecated.partition.lastUpdate","title":"<code>lastUpdate()</code>  <code>method descriptor</code>","text":"<p>Return time (epoch seconds) the partition data was updated.</p> <p>Returns:</p> Type Description <code>int</code> <p>Epoch seconds</p>"},{"location":"reference/old/partition/#pyslurm.deprecated.partition.print_info_msg","title":"<code>print_info_msg(oneLiner=0)</code>  <code>method descriptor</code>","text":"<p>Display partition information from previous load partition method.</p> <p>Parameters:</p> Name Type Description Default <code>oneLiner</code> <code>int</code> <p>Display on one line.</p> <code>0</code>"},{"location":"reference/old/partition/#pyslurm.deprecated.partition.update","title":"<code>update(Partition_dict)</code>  <code>method descriptor</code>","text":"<p>Update a slurm partition.</p> <p>Parameters:</p> Name Type Description Default <code>Partition_dict</code> <code>dict</code> <p>A populated partition dictionary, an empty one is created by create_partition_dict</p> required <p>Returns:</p> Type Description <code>int</code> <p>0 for success, -1 for error, and the slurm error code is set   appropriately.</p>"},{"location":"reference/old/db/job/","title":"Job","text":"<p>Warning</p> <p>This is superseded by pyslurm.db.Job class and will be removed in a future release</p>"},{"location":"reference/old/db/job/#pyslurm.deprecated.slurmdb_jobs","title":"<code>pyslurm.deprecated.slurmdb_jobs</code>","text":"<p>Access Slurmdbd Jobs information.</p>"},{"location":"reference/old/db/job/#pyslurm.deprecated.slurmdb_jobs.get","title":"<code>get(jobids=[], userids=[], starttime=0, endtime=0, flags=None, db_flags=None, clusters=[])</code>  <code>method descriptor</code>","text":"<p>Get Slurmdb information about some jobs.</p> Input formats for start and end times <ul> <li>today or tomorrow</li> <li>midnight, noon, teatime (4PM)</li> <li>HH:MM [AM|PM]</li> <li>MMDDYY or MM/DD/YY or MM.DD.YY</li> <li>YYYY-MM-DD[THH[:MM[:SS]]]</li> <li>now + count [minutes | hours | days | weeks] *</li> </ul> <p>Invalid time input results in message to stderr and return value of zero.</p> <p>Parameters:</p> Name Type Description Default <code>jobids</code> <code>list</code> <p>Ids of the jobs to search. Defaults to all jobs.</p> <code>[]</code> <code>starttime</code> <code>int</code> <p>Select jobs eligible after this timestamp</p> <code>0</code> <code>endtime</code> <code>int</code> <p>Select jobs eligible before this timestamp</p> <code>0</code> <code>userids</code> <code>list</code> <p>List of userids</p> <code>[]</code> <code>flags</code> <code>int</code> <p>Flags</p> <code>None</code> <code>db_flags</code> <code>int</code> <p>DB Flags</p> <code>None</code> <code>clusters</code> <code>list</code> <p>List of clusters</p> <code>[]</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary whose key is the JOBS ID</p>"}]}